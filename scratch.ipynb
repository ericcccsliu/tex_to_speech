{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91973420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T18:39:19.775440Z",
     "start_time": "2024-03-02T18:39:19.765440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "66ad0f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:55:46.603857Z",
     "start_time": "2024-03-02T19:55:46.327750Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "682a3eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:55:46.609151Z",
     "start_time": "2024-03-02T19:55:46.606343Z"
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226db095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T18:39:40.836419Z",
     "start_time": "2024-03-02T18:39:40.793629Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8dac8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T18:40:04.322948Z",
     "start_time": "2024-03-02T18:40:04.317587Z"
    }
   },
   "source": [
    "## prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "532cdadc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T18:45:10.467482Z",
     "start_time": "2024-03-02T18:45:10.462710Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are a large language model that is an expert at taking scientific and mathematical research papers, typeset in LaTeX, and transcribing them in spoken English, for the purpose of generating audio content. Please transcribe the following paper, typeset in LaTeX, into a format that will sound coherent when read by a text-to-speech program.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77d803",
   "metadata": {},
   "source": [
    "Please take the following LaTeX code and transcribe all content into a format optimized for text-to-speech. All text content should be preserved or transcribed into a easily readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8eec7509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:03:52.373231Z",
     "start_time": "2024-03-02T20:03:52.368646Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = r\"\"\"I want to generate a podcast from LaTeX code. Please take the following LaTeX code and transcribe all content into a format optimized for text-to-speech. Do not make any effort to summarize or compress content–all original words by the author must be preserved. All text content should be preserved or transcribed into a easily readable format. Equations and math should be transcribed such that they are human readable in text. For example, $a^2$ should be transcribed as 'a squared'. Furthermore, all commands should also be transcribed to readable text. For example, commands such as \\section and \\title should be read as 'section' and 'title' respectively, and \\cite or \\citet should transcribe the citation as an in-text citation. Figures must be omitted in their entirety.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f4a0445d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:03:53.066704Z",
     "start_time": "2024-03-02T20:03:53.062535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to generate a podcast from LaTeX code. Please take the following LaTeX code and transcribe all content into a format optimized for text-to-speech. Do not make any effort to summarize or compress content–all original words by the author must be preserved. All text content should be preserved or transcribed into a easily readable format. Equations and math should be transcribed such that they are human readable in text. For example, $a^2$ should be transcribed as 'a squared'. Furthermore, all commands should also be transcribed to readable text. For example, commands such as \\section and \\title should be read as 'section' and 'title' respectively, and \\cite or \\citet should transcribe the citation as an in-text citation. Figures must be omitted in their entirety.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738a691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T18:51:48.151253Z",
     "start_time": "2024-03-02T18:51:48.147777Z"
    }
   },
   "source": [
    "#### chonk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b2f2e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:05:02.245798Z",
     "start_time": "2024-03-02T19:05:02.204866Z"
    }
   },
   "outputs": [],
   "source": [
    "chonk = r\"\"\"\n",
    "\\documentclass[discussion]{clv3}\n",
    "\n",
    "\\usepackage{hyperref}\n",
    " \\usepackage{soul}\n",
    "\\usepackage{xcolor}\n",
    "\\definecolor{darkblue}{rgb}{0, 0, 0.5}\n",
    "\\hypersetup{colorlinks=true,citecolor=darkblue, linkcolor=darkblue, urlcolor=darkblue}\n",
    "\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{framed}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{cleveref}\n",
    "\\usepackage{subcaption}\n",
    "\\usepackage[compact]{titlesec}\n",
    "\n",
    "\n",
    "\\bibliographystyle{compling}\n",
    "\n",
    "% test compatibility with algorithmic.sty\n",
    "%\\usepackage{algorithmic}\n",
    "\n",
    "\\issue{1}{1}{2016}\n",
    "\n",
    "%Document Head\n",
    "\\dochead{Squib}\n",
    "\n",
    "\\runningtitle{Probing Classifiers}\n",
    "\n",
    "\\runningauthor{Yonatan Belinkov}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\title{Probing Classifiers: Promises, Shortcomings, and Advances}\n",
    "\n",
    "\\historydates{Submission received: 4 March 2021; \n",
    "             revised version received: 31 July 2021; \n",
    "             accepted for publication:  8 September 2021}\n",
    "\n",
    "\\author{Yonatan Belinkov\\thanks{Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion.}}\n",
    "\\affil{Technion -- Israel Institute of Technology \\\\ {\\tt belinkov@technion.ac.il}}\n",
    "\n",
    "% \\author{Another Author\\thanks{PITC Building}}\n",
    "% \\affil{Publishing / SPi}\n",
    "\n",
    "% \\author{And Another Author}\n",
    "% \\affil{Publishing / SPi}\n",
    "\n",
    "% \\author{And Yet Another}\n",
    "% \\affil{Publishing / SPi}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "\\begin{abstract}\n",
    "Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple --- a classifier is trained to predict some linguistic property from a model's representations --- and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This article critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances. \n",
    "\\end{abstract}\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "\\looseness=-1\n",
    "The opaqueness of deep neural network models of natural language processing (NLP) has spurred a line of research into interpreting and analyzing them. \n",
    "Analysis methods may aim to answer questions about a model's structure or its decisions. For instance, one might  ask which parts of a neural neural model are responsible for certain linguistic properties, or which parts of the input led the model to make a certain decision. \n",
    "A common methodology to answer questions about the structure of models is to associate internal representations with external properties, by training a classifier on said representations that predicts a given property. This framework, known as \\mbox{\\textbf{probing classifiers}}, has emerged as a prominent analysis strategy in many studies of NLP models.\\footnote{For an overviews of analysis methods in NLP, see the survey by \\citet{belinkov-glass-2019-analysis}, as well as the tutorials by \\citet{belinkov-etal-2020-interpretability} and \\citet{wallace-etal-2020-interpreting}. For an overview of explanation methods in particular, see the survey by \\citet{danilevsky-etal-2020-survey}.}  \n",
    "\n",
    "\\looseness=-1\n",
    "Despite its apparent success, the probing classifiers paradigm is not without limitations. Critiques have been made about comparative baselines, metrics, the choice of classifier, and the correlational nature of the method. In this short article, we first define the probing classifiers framework, taking care to consider the various involved components. Then we summarize the framework's shortcomings, as well as improvements and advances. \n",
    "This article provides a roadmap for NLP researchers who wish to examine probing classifiers more critically and highlights areas in need of additional research. \n",
    "\n",
    "\n",
    "\\section{The Probing Classifiers Framework} \\label{sec:framework} \n",
    "\n",
    "\n",
    "\n",
    "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property. \n",
    "%\n",
    "However, upon closer inspection, it turns out that much more is involved here. To see this, we now define this framework a bit more formally. \n",
    "\n",
    "Let us denote by $f : x \\mapsto \\hat{y}$ a model that maps input $x$ to output $\\hat{y}$. We call this model the original model. It is trained on some annotated dataset $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\}$, which we refer to as the original dataset. Its performance is evaluated by some measure, denoted $\\textsc{Perf}(f, \\mathcal{D}_O)$.\n",
    "The function $f$ is typically a deep neural network that generates intermediate representations of $x$, for example $f_l(x)$ may denote the representation of $x$ at layer $l$ of $f$.\\footnote{We use $f_l(x)$ to refer more generally to any intermediate output of $f$ when applied to $x$, so the framework includes analyses of other model components, such as attention weights \\cite{clark-etal-2019-bert}.} \n",
    "A probing classifier $g : f_l(x) \\mapsto \\hat{z}$ maps intermediate representations to some property $\\hat{z}$, which is typically some linguistic feature of interest. \n",
    "As a concrete example, $f$ might be a sentiment analysis model, mapping a text $x$ to a sentiment label  $y$, while $g$ might be a classifier mapping intermediate representations $f_l(x)$ to part-of-speech tags $z$.\n",
    "The classifier $g$ is trained and evaluated on some annotated dataset $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\}$, and some performance measure $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ (e.g., accuracy) is reported. Note that the performance measure depends on the probing classifier $g$ and the probing dataset $\\mathcal{D}_P$, as well as on the original model $f$ and the original dataset $\\mathcal{D_O}$.  \n",
    "\n",
    "\n",
    "From an information theoretic perspective, training the probing classifier $g$ can be seen as estimating the mutual information between the intermediate representations $f_l(x)$ and the property $z$ (\\citealt[p. 42]{belinkov:2018:phdthesis}; \\citealt{pimentel-etal-2020-information}; \\citealt{zhu-rudzicz-2020-information}), which we write $\\mathrm{I}(\\mathbf{z} ; \\mathbf{h})$, where  $\\mathbf{z}$ is a random variable ranging over properties $z$ and $\\mathbf{h}$ is a random variable ranging over representations $f_l(x)$.  \n",
    "\n",
    "The above careful definition of the probing classifiers framework reveals that it is comprised of multiple concepts and components, depicted in \\Cref{fig:probing-components-basic}.  The choice of each such component, and the interactions between them, lead to non-trivial questions regarding the design and implementation of any probing classifier experiment. Before we turn to these considerations   in \\Cref{sec:shortcomings-advances}, we briefly review some history and promises of probing classifiers in the next section. \n",
    "\n",
    "\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    % \\begin{framed}\n",
    "    \\begin{subfigure}[b]{\\textwidth}\n",
    "    \\centering\n",
    "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
    "        % \\centering\n",
    "        \\toprule\n",
    "         $x \\mapsto y$ & Original task \\\\\n",
    "         $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\} $ & Original dataset \\\\\n",
    "         $f : x \\mapsto y $ & Original model \\\\\n",
    "         $\\textsc{Perf}(f, \\mathcal{D}_O)$ & Performance on the original task \\\\\n",
    "         $f_l(x)$ & Representations of $x$ from $f$\\\\\n",
    "         $f_l(x) \\mapsto z$ & Probing task \\\\\n",
    "         $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\} $ & Probing dataset \\\\\n",
    "         $g : f_l(x) \\mapsto z$ & Probing classifier \\\\\n",
    "         $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) $ & Probing performance  \\\\ \n",
    "         \\bottomrule\n",
    "        \\end{tabular}\n",
    "         \\caption{Basic Components.}\n",
    "         \\label{fig:probing-components-basic}\n",
    "     \\end{subfigure}\n",
    "     \\begin{subfigure}[b]{\\textwidth}\n",
    "     \\centering\n",
    "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
    "        \\toprule          \n",
    "         $\\bar{f} : x \\mapsto y$ & Skyline model or upper bound \\\\ \n",
    "         $\\underline{f} : x \\mapsto y$ & Baseline model \\\\          \n",
    "         $x \\mapsto y_{Rand}$ & Control task \\cite{hewitt-liang-2019-designing} \\\\ \n",
    "         $c : f_l(x) \\mapsto c(f_l(x)) $ & Control function \\cite{pimentel-etal-2020-information} \\\\ \n",
    "         $\\mathcal{D}_{P,Rand}$ & Control task dataset \\cite{hewitt-liang-2019-designing} \\\\ \n",
    "         $\\mathcal{D}_{O,z}$ & Control dataset \\cite{ravichander:2021:eacl} \\\\          \n",
    "         $\\textsc{Sel}(g, f, \\mathcal{D}_O, \\mathcal{D}_P, \\mathcal{D}_{P,Rand})$ & Probing selectivity \\cite{hewitt-liang-2019-designing} \\\\\n",
    "         $ \\mathcal{G}(\\mathbf{z}, \\mathbf{h}, c) $ & Information gain w.r.t control function \\cite{pimentel-etal-2020-information} \\\\ \n",
    "         $\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ & Probe minimum description length \\cite{voita-titov-2020-information} \\\\ \n",
    "         $\\tilde{f}_l(x)$ & Representations of $x$ from $f$, after an intervention \\\\ \n",
    "         \\bottomrule \n",
    "        \\end{tabular}\n",
    "        \\caption{Additional Components.}\n",
    "        \\label{fig:probing-components-extended}\n",
    "        \\vspace{-3pt}\n",
    "    \\end{subfigure}\n",
    "    \\caption{Components comprising the probing classifiers framework.}\n",
    "    \\label{fig:probing-components}\n",
    "    \\vspace{-19pt}\n",
    "\\end{figure}\n",
    "\n",
    "\n",
    "\n",
    "\\section{Promises} \\label{sec:promises}\n",
    "\n",
    "\n",
    "\\looseness=-1\n",
    "Perhaps the first studies that can be cast in the framework of probing classifiers are by \\citet{kohn-2015-whats} and \\citet{gupta-etal-2015-distributional}, who trained classifiers on static word embeddings to predict various morphological, syntactic, and semantic properties. Their goals were to provide more nuanced evaluations of word embeddings compared to prior work, which only integrated them in downstream tasks.  \n",
    "Other early work classified hidden states of a recurrent neural network machine translation system into morpho-syntactic properties \\cite{shi-etal-2016-string}. They were motivated by the end-to-end nature of the neural machine translation system, which, compared to a phrase/syntax-based system, did not explicitly integrate such properties (so they ask: ``What kind of syntactic information is learned, and how much?'').  \n",
    "The framework has taken up a more stable form by several groups who studied sentence embeddings \\cite{ettinger-etal-2016-probing,adi:2017:ICLR,conneau-etal-2018-cram}  and recurrent/recursive neural networks \\cite{belinkov-etal-2017-neural,hupkes2018visualisation}.\\footnote{For chronological completeness, workshop and preprint versions of \\citet{hupkes2018visualisation} and \\citet{adi:2017:ICLR} appeared earlier \\cite{veldhoen2016diagnostic,DBLP:journals/corr/AdiKBLG16}.}  The same idea had been concurrently proposed for investigating computer vision models \\cite{alain2016understanding}. \n",
    "\n",
    "\n",
    "A main motivation in this body of work is the \\emph{opacity} of the representations.\\footnote{``little is known about the information that is captured by different sentence embedding learning mechanisms'' \\cite{adi:2017:ICLR}; ``a poor understanding of what they are capturing'' \\cite{conneau-etal-2018-cram}; ``little is known about what and how much these models learn.'' %about each language and its features''\n",
    "\\cite{belinkov-etal-2017-neural}.} \n",
    "Compared to performance on downstream tasks, probing classifiers aim to provide more nuanced evaluations w.r.t \\emph{simple properties}.\\footnote{``fine-grained measurement of some of the information encoded in sentence embeddings'' \\cite{adi:2017:ICLR}; ``simple linguistic properties of sentences'' \\cite{conneau-etal-2018-cram}; ``assessing the specific semantic information that is being captured in sentence representations'' \\cite{ettinger-etal-2016-probing}.} \n",
    "Indeed, following the initial studies, a plethora of work has applied the framework to various models and properties, alleviating some of the opacity, at least in terms of properties encoded in the representations. See \\citet{belinkov-glass-2019-analysis} for a comprehensive survey up to early 2019.\\footnote{There have also been numerous other studies using the probing classifier framework as is. For a partial list, see \\url{https://github.com/boknilev/nlp-analysis-methods/issues/5}. For recent analyses focusing on the BERT model \\cite{devlin-etal-2019-bert}, see  \\citet{rogers-etal-2020-primer}.}  \n",
    "\n",
    "However, what can be inferred from successful probing performance is less obvious. \n",
    "Good probing performance is often taken to indicate several potential situations: \n",
    "good  \\emph{quality} of the representations w.r.t the probing property,\\footnote{``evaluate the quality of the trained classifier on the given task as a proxy to the quality of the extracted representations'' \\cite{belinkov-etal-2017-neural}.}\n",
    "\\emph{readability} of information found in the representations,\\footnote{``If the classifier succeeds, it means that the pre-trained encoder is storing readable tense information into the embeddings it creates'' \\cite{conneau-etal-2018-cram}.}   \n",
    "or its \\emph{extractability}.\\footnote{``testing for extractability of semantic information by testing classification accuracy..'' \\cite{ettinger-etal-2016-probing}; ``if a sequential model is computing certain information, or merely keeping track of it, it should be possible to extract this information from its internal state space'' \\cite{hupkes2018visualisation}.}\n",
    "In contrast, low probing performance is taken to indicate that the probing property is not present in the representations or is not usable.\\footnote{``low accuracy suggests this information is not represented in the hidden state'' \\cite{hupkes2018visualisation}; ``if we cannot train a classifier to predict some property of a sentence based on its vector representation, then this property is not encoded in the representation (or rather, not encoded in a useful way, considering how the representation is likely to be used)'' \\cite{adi:2017:ICLR}.} \n",
    "%\n",
    "Sometimes, good  performance is taken to indicate \\emph{how} the original model achieves its behavior on the original task \\cite{hupkes2018visualisation}. A linear probing classifier is thought to reveal features that are used by the original model, while a more complex probe ``bears the risk that the classifier infers features that are not actually used by the network'' \\cite{hupkes2018visualisation}.  \n",
    "Often, different terms (\\emph{quality}, \\emph{readability}, \\emph{usability}, etc.) appear abstractedly without precise definitions. \n",
    "\n",
    "\n",
    "As we shall see, some of the above assumptions and conclusions are better accounted for than others by the probing classifiers paradigm. \n",
    "Indeed, the community has recently taken a more critical look at the methodology, which we turn to now.\n",
    "\n",
    "\n",
    "\\section{Shortcomings and Advances} \\label{sec:shortcomings-advances} \n",
    "\n",
    "\n",
    "In light of the promises discussed above, this section reviews several limitations of the probing classifiers framework, as well as existing proposals for addressing them. We discuss comparisons and controls, how to choose the probing classifier, which causal claims can be made, the difference between datasets and tasks, and the need to define the probed properties. \n",
    "We formalize new additional components (\\Cref{fig:probing-components-extended}) in a unified framework, along with the basic components (\\Cref{fig:probing-components-basic}). \n",
    "\n",
    "\n",
    "\\subsection{Comparisons and controls} \n",
    "\n",
    "A first concern with the framework is how to interpret the results of a probing classifier experiment. \n",
    "Suppose we run such an experiment and obtain a performance of $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) = 87.8$. Is that a high/low number? What should we compare it to? \n",
    "We will denote a baseline model with $\\underline{f}$ and an upper bound or skyline model with $\\bar{f}$. \n",
    "\n",
    "Some studies compare with majority baselines \\cite{belinkov-etal-2017-neural,conneau-etal-2018-cram} or with classifiers trained on representations that are thought to be simpler than what the original model $f$ produces, such as static word embeddings \\cite{belinkov-etal-2017-neural,tenney2018what}.  Others advocate for random baselines, training the classifier $g$ on a randomized version of $f$ \\cite{conneau-etal-2018-cram,zhang-bowman-2018-language,tenney2018what,chrupala-etal-2020-analyzing}. These studies show that even random features capture significant information that can be decoded by the probing classifier, so performance on learned features should be viewed in such a perspective. \n",
    "\n",
    "On the other hand, some studies compare $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ to skylines or upper bounds $\\bar{f}$, in an attempt to provide a point of comparison for how far probing performance is from the possible performance on the task of mapping $x \\mapsto z$. \n",
    "Examples include estimating human performance \\cite{conneau-etal-2018-cram}, reporting the state of the art from the literature \\cite{liu-etal-2019-linguistic}, or training a dedicated model to predict $z$ from $x$, without restricting to (frozen) representations from $f$ \\cite{belinkov-etal-2017-evaluating}. \n",
    "\n",
    "\n",
    "Others have proposed to design controls for possible confounders. \\citet{hewitt-liang-2019-designing} observe that the probing performance  $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ may tell us more about the probe $g$ than about the model $f$. The probe $g$ may memorize information from $\\mathcal{D}_P$, rather than evaluate information found in representations $f(x)$.   They design control tasks, which a probe may only solve by memorizing. In particular, they randomize the labels in  $\\mathcal{D}_P$, creating a new dataset  $\\mathcal{D}_{P,Rand}$. Then, they define \\emph{selectivity} as the difference between the probing performance on the probing task and the control task:  $\\textsc{Sel}(g, f, \\mathcal{D}_O, \\mathcal{D}_P, \\mathcal{D}_{P,Rand})$ =  $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) - \\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_{P,Rand})$. They show that probes may have high accuracy, but low selectivity, and that linear probes tend to have high selectivity, while non-linear probes tend to have low selectivity. This indicates that high accuracy of non-linear probes may come from memorization of surface patterns by the probe $g$, rather than from information captured in the representations $f_l(x)$. \n",
    "The control tasks introduced by \\citeauthor{hewitt-liang-2019-designing} are particularly suited for word-level properties $z$ as they evaluate memorization of word types; it is less clear how to apply this idea more broadly, such as in sentence-level properties. \n",
    "\n",
    "Taking an information-theoretic perspective on probing, \\citet{pimentel-etal-2020-information} proposed to use control functions instead of control tasks in order to compare probes. Their control function is any function applied to the representation, $c : f_l(x) \\mapsto c(f_l(x))$, and they compare the information gain, which is the difference in mutual information between the property $z$ and the representation before and after applying the control function:  $ \\mathcal{G}(\\mathbf{z}, \\mathbf{h}, c) =   \\mathrm{I}(\\mathbf{z} ; \\mathbf{h}) - \\mathrm{I}(\\mathbf{z} ; \\mathbf{c(h)})$. \n",
    "While \\citet{pimentel-etal-2020-information} posit that their control function are a better criterion than the control tasks of \\citet{hewitt-liang-2019-designing}, subsequent work showed that the two criteria are almost equivalent, both theoretically and empirically \\cite{zhu-rudzicz-2020-information}. \n",
    "\n",
    "\n",
    "Another kind of control is proposed by \\citet{ravichander:2021:eacl}, who design control datasets, where the linguistic property $z$ is not discriminative w.r.t the original task of mapping $x$ to $y$. That is, they modify $\\mathcal{D}_O$ and create a new dataset, $\\mathcal{D}_{O,z}$, where all examples have the same value for property $z$. Intuitively, a model $f$ trained on $\\mathcal{D}_{O,z}$ should not pick up information about $z$, since it is not useful for the task of $f$. They show that a probe $g$ may learn to predict property $z$ incidentally, even when it is not discriminative w.r.t the original task of mapping $x \\mapsto y$, casting doubts on causal claims concerning the effect that a property encoded in the representation may have on the original task. While they create control datasets for probing sentence-level information, the same idea can be applied to word-level properties.  \n",
    "\n",
    "\n",
    "\n",
    "\\subsection{Which classifier to use?}\n",
    "\n",
    "\n",
    "Another concern is the choice of the probing classifier $g$: \n",
    "What should be its structure? What role does its expressivity play in drawing conclusions about the original model $f$? \n",
    "\n",
    "Some studies advocate for using simple probes, such as linear classifiers \\cite{alain2016understanding,hupkes2018visualisation,liu-etal-2019-linguistic,hall-maudslay-etal-2020-tale}. Somewhat anecdotally, a few studies observed better performance with more complex probes, but reported similar relative trends \\cite{conneau-etal-2018-cram,belinkov:2018:phdthesis}. That is, a ranking \n",
    " $\\textsc{Perf}(g, f_1, \\mathcal{D}_O, \\mathcal{D}_P) > \\textsc{Perf}(g, f_2, \\mathcal{D}_O, \\mathcal{D}_P)$, of two representations $f_1(x)$ and $f_2(x)$,  holds across different probes $g$. \n",
    "However, this pattern may be flipped under alternative measures, such as selectivity \\cite{hewitt-liang-2019-designing}. \n",
    "\n",
    "Several studies considered the complexity of the probe $g$ in more detail. \\citet{pimentel-etal-2020-information} argue that, in order to give the best estimate about the information that model $f$ has about property $z$, the most complex probe should be used. \n",
    "In a more practical view, \\citet{voita-titov-2020-information} propose to measure both the performance of the probe $g$ and its complexity, by estimating the minimum description length of the code required to transmit property $z$ knowing the representations $f_l(x)$: \n",
    "$\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$.\n",
    "Note that this measure again depends on the probe $g$, the model $f$, and their respective datasets $\\mathcal{D}_O$ and  $\\mathcal{D}_P$. \n",
    "They found that MDL provides more information about how a probe $g$ works, for instance by revealing differences in complexity of probes when performing control tasks from $\\mathcal{D}_{P,Rand}$, as in \\citet{hewitt-liang-2019-designing}. \n",
    " \\citet{pimentel-etal-2020-pareto} argue that probing work should report the possible trade-offs between accuracy and complexity, along a range of probes $g$, and call for using probes that are both simple and accurate. \n",
    "While they study a number of linear and  non-linear multi-layered perceptrons, one could extend this idea to other classes of probes. Indeed, \\citet{cao2021low} design a pruning-based probe, which learns a mask on weights of $f$ and obtains a  better accuracy--complexity trade-off than a non-linear probe. \n",
    "\n",
    " \n",
    "\n",
    "Another line of work proposes methods to extract linguistic information from a trained model without learning additional parameters. In particular, much work has used some sort of pairwise importance score between words in a sentence as a signal for inferring linguistic properties, either full syntactic parsing or more fine-grained properties such as coreference resolution. These scores may come from attention weights \\cite{raganato-tiedemann-2018-analysis,clark-etal-2019-bert,marecek-rosa-2019-balustrades,htut2019attention} or from distances between word representations, perhaps including perturbations of the input sentence \\cite{wu-etal-2020-perturbed}.   The pairwise scores can feed into some general parsing algorithm, such as the Chu-Liu Edmonds algorithm \\citeyearpar{10030090917,edmonds1967optimum}.  Alternatively, some work has used representational similarity analysis \\cite{10.3389/neuro.06.004.2008} to measure similarity between word or sentence representations and syntactic properties, both local properties like determining a verb's subject \\cite{lepori-mccoy-2020-picking} and more structured properties like inferring the full syntactic tree \\cite{chrupala-alishahi-2019-correlating}. Also related is work on clustering representations w.r.t linguistic property and classifying by cluster assignment \\cite{zhou-srikumar-2021}.  \n",
    "This line of work can be seen as a parameter-less probing classifier $g$: a linguistic property is inferred from internal model components (representations, attention weights), without needing to learn new parameters. Thus, such work avoids some of the issues about what the probe learns. Additionally, from the perspective of an accuracy--complexity trade-off, such work should perhaps be placed on the low end of the complexity axis, although the complexity of the parsing algorithm could also be taken into account.  \n",
    "\n",
    "\n",
    "\\subsection{Correlation vs.\\ causation} \\label{sec:causal}\n",
    "\n",
    "\n",
    "\n",
    "A main limitation of the probing classifier paradigm is the disconnect between the probing classifier $g$ and the original model $f$. They are trained in two different steps, where $f$ is trained once and only used to generate feature representations $f_l(x)$, which are fed into $g$. Once we have $f_l(x)$, we get a probing performance from $g$, which tells us something about the information in  $f_l(x)$. However, in the process, we have forgotten about the original task assigned to $f$, which was to predict $y$. This raises an important question, which early work has largely taken for granted (\\Cref{sec:promises}): \n",
    "Does model $f$ use the information discovered by probe $g$? \n",
    "In other words, the probing framework may indicate correlations between representations $f_l(x)$ and linguistic property $z$, but it does not tell us whether this property is involved in predictions of $f$. \n",
    "Indeed, several studies pointed out this limitation \\cite{belinkov-glass-2019-analysis}, including reports on a mismatch between performance of the probe, $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$, and performance of the original model, $\\textsc{Perf}(f, \\mathcal{D}_O)$  \\cite{VanmassenhoveDuWay2017}. \n",
    "In contrast, \\citet{lovering2021predicting} find that extractability of a property according to $\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ is correlated with $f$ making predictions consistent with that property. \n",
    "Relatedly, \\citet{tamkin-etal-2020-investigating} find a discrepancy between features $f_l(x)$ obtaining high probing performance, $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$, and features identified as important when fine-tuning $f$ while performing the probing task $f_l(x) \\mapsto z$. They reveal this by randomizing the weights of specific layers when fine-tuning $f$, which can be seen as a kind of intervention.\n",
    "\n",
    "\n",
    "Indeed, a number of studies have proposed improvements to the probing classifier paradigm, which aim to discover causal effects by \\emph{intervening} in representations of the model $f$. \n",
    "\\citet{giulianelli-etal-2018-hood} use gradients from $g$ to modify the representations in $f$ and evaluate how this change affects both the probing performance and the original model performance. In their case, $f$ is a language model and $g$ predicts subject--verb number agreement. They find that their intervention increases probing performance, as may be expected. Interestingly, while in the general language modeling case the intervention has a small effect on the original model performance, $\\textsc{Perf}(f, \\mathcal{D}_O)$, they find an increase in this performance on examples designed to assess number agreement. They conclude that probing classifiers can identify features that are actually used by the model. \n",
    "\\citet{tucker2021modified} also use probe gradients to update the representations $f_l(x)$ w.r.t $z$, resulting in what they call counterfactual representations, and measure the effect on other properties. \n",
    "Similarly, \\citet{elazar2020amnesic} remove certain properties $z$ (such as parts of speech or syntactic dependencies) from representations in $f$ by repeatedly training (linear) probing classifiers $g$ and projecting them out of the representation. This results in a modified representation $\\tilde{f}_l(x)$, which has less information about $z$.  They compare the probing performance to the performance on the original task (in their case, language modeling) after the removal of said features. They find that high probing performance $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ does not necessarily entail a large drop in original task performance after their removal, that is, $\\textsc{Perf}(\\tilde{f}, \\mathcal{D}_O)$. Thus, contrary to \\citet{giulianelli-etal-2018-hood}, they conclude that probing classifiers do not always identify features that are actually used by the model. \n",
    "In a similar vein, \\citet{feder2020causalm} remove properties $z$ from representations in $f$ by training $g$ adversarially. \n",
    "At the same time, another probing classifier $g_C$ is trained positively, aiming to control for properties $z_C$ that should not be removed from $f$. A major difference from standard probing classifiers work is the continued updating of $f$. They find that they can accurately estimate the effect of properties $z$ on downstream tasks performed by $f$ when it is fine-tuned.\\footnote{Other studies that perform interventions to interpret NLP models without involving probing classifiers \\cite[e.g.,][]{bau2018identifying,lakretz-etal-2019-emergence,vig:2020:neurips} are left out of the present scope.}\n",
    "\n",
    "\n",
    "\n",
    "\\subsection{Datasets vs.\\ tasks}\n",
    "\n",
    "\n",
    "The probing paradigm aims to study models performing some task ($f : x \\mapsto \\hat{y}$) via a classifier performing another task ($g: f_l(x) \\mapsto \\hat{z}$). However, in practice these \\emph{tasks} are operationalized via finite \\emph{datsaets}. \n",
    "\\citet{ravichander:2021:eacl}  point out that datasets are imperfect proxies for tasks. \n",
    "Indeed, \n",
    "the effect of the choice of datasets---both the original dataset $\\mathcal{D}_O$ and the probing dataset $\\mathcal{D}_P$---has not been widely studied. Furthermore, we ideally want to disentangle the role of each dataset from the role of the original model $f$ and probing classifier $g$. \n",
    "Unfortunately, models $f$ tend to be trained on different datasets $\\mathcal{D}_O$, making statements about models confounded with issues of datasets. Some prior work acknowledged that conclusions can only be made about the existing \\emph{trained models}, not about general \\emph{architectures} \\cite{liu-etal-2019-linguistic}. \n",
    "However, in an ideal world, we would compare different architectures $\\{f^i\\}$ trained on the same dataset $\\mathcal{D}_O$  or the same  $f$ trained on different datasets $\\{\\mathcal{D}_O^i\\}$. \n",
    "Concerning the latter, \\citet{zhang-etal-2021-need} found that models require less data to encode syntactic and semantic properties compared to commonsense knowledge.\n",
    "More such experiments are currently lacking.  \n",
    "\n",
    "The effect of the probing dataset $\\mathcal{D}_P$---its size, composition, etc.---is similarly not well studied. While some work reported results on multiple datasets when predicting the same property $z$ \\cite[e.g.,][]{belinkov-etal-2017-neural}, more careful investigations are needed. \n",
    "\n",
    "\n",
    "\\subsection{Properties must be pre-defined}\n",
    "\n",
    "\n",
    "Finally, \n",
    "inherent to the probing classifier framework is determining a property $z$ to probe for. This limits the investigation in multiple ways: It constrains the work to existing annotated datasets, which are often limited to English and certain properties. It also requires focusing on properties $z$ that are thought to be relevant to the task of mapping $x \\mapsto y$ a-priori, potentially leading to biased conclusions.\n",
    "In an isolated effort to alleviate this limitation, \\citet{michael-etal-2020-asking} propose to learn latent clusters useful for predicting a property $z$. They discover clusters corresponding to known properties (such as personhood) as well as new categories, which are not usually annotated in common datasets. Still, probing classifiers are so far mainly useful when one has prior expectations about which properties $z$ might be relevant w.r.t a given task. \n",
    "\n",
    "\n",
    "\\section{Summary}\n",
    "\n",
    "\n",
    "Given the various limitations discussed in this article, one might ask: \n",
    "What are probing classifiers good for? In line with the original motivation to alleviate the \\emph{opacity} of learned representations, work using probing classifiers has characterized them along a range of fine-grained properties. \n",
    "However, we have discussed several reservations regarding which insights can be drawn from a probing classifier experiment. \n",
    "Absolute claims about representation \\emph{quality} seem difficult to make. \n",
    "Yet recent improvements to the framework, such as better controls and metrics, allow us to make relative claims and answer questions like how \\emph{extractable} a property is from a representation.  \n",
    "And causal approaches (\\Cref{sec:causal}) may reveal which properties are \\emph{used} by the original model. \n",
    "\n",
    "\n",
    "One might hope that probing classifier experiments would suggest ways to improve the quality of the probed model or to direct it to be better tuned to some use or task. Presently, there are few such successful examples. For instance, {earlier results showing that lower layers in language models focus on local phenomena while higher layers focus on global ones (using probing classifiers and other methods) motivated \\citet{cao-etal-2020-deformer} to decouple a question-answering model, such that lower layers process the question and the passage independently and higher layers process them jointly. \n",
    "An analysis of redundancy in language models (again using probing classifiers and other methods) motivated an efficient transfer-learning procedure \\cite{dalvi-etal-2020-analyzing}. \n",
    "An analysis of phonetic information in layers of a speech recognition systems \\cite{NIPS2017_b069b341} partly motivated \\citet{krishna2018hierarchical} to propose multi-task learning with phonetic supervision on intermediate layers.  \n",
    " \\citet{belinkov-etal-2020-linguistic} discuss how their probing experiments can guide the selection of which machine translation models to use when translating specific languages. \n",
    "Finally, when considering using the representations for some downstream task, probing experiments can indicate which information is encoded, or can easily be extracted, from these representations. \n",
    "\n",
    "\n",
    "\n",
    "To conclude, our critical review of the probing classifiers framework reveals that it is more complicated than may seem. \n",
    "When designing a probing classifier experiment, we advise researchers to take the various controls and alternative measures into account. Naturally, one should clearly define the original task/dataset/model and the probing task/dataset/classifier. It is important to set upper and lower bounds, and to consider proper controls, via either control tasks (for word-level properties) or datasets (for sentence-level properties). Depending on goals, one may want to measure the probe's complexity (if ease of extractability is in question), report the accuracy--complexity trade-off (when designing new probes), or perform an intervention (to measure usage of information by the original model). When possible, using parameter-free probes may circumvent some of the challenges with parameterized probes. \n",
    "We do not argue that every study must perform all the various controls and report all the alternative measures summarized here. \n",
    "However, future work seeking to use probing classifiers would do well to take into account the complexity of the framework, its apparent shortcomings, and available advances. \n",
    "\n",
    "\n",
    "\\begin{acknowledgments}\n",
    "This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 448/20) and by an Azrieli Foundation Early Career Faculty Fellowship.\n",
    "\\end{acknowledgments}\n",
    "\n",
    "\n",
    "\n",
    "\\starttwocolumn\n",
    "\\bibliography{compling_style}\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d0d365a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:04:16.014090Z",
     "start_time": "2024-03-02T20:04:16.006741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\documentclass[discussion]{clv3}\n",
      "\n",
      "\\usepackage{hyperref}\n",
      " \\usepackage{soul}\n",
      "\\usepackage{xcolor}\n",
      "\\definecolor{darkblue}{rgb}{0, 0, 0.5}\n",
      "\\hypersetup{colorlinks=true,citecolor=darkblue, linkcolor=darkblue, urlcolor=darkblue}\n",
      "\n",
      "\\usepackage{amsmath}\n",
      "\\usepackage{framed}\n",
      "\\usepackage{booktabs}\n",
      "\\usepackage{cleveref}\n",
      "\\usepackage{subcaption}\n",
      "\\usepackage[compact]{titlesec}\n",
      "\n",
      "\n",
      "\\bibliographystyle{compling}\n",
      "\n",
      "% test compatibility with algorithmic.sty\n",
      "%\\usepackage{algorithmic}\n",
      "\n",
      "\\issue{1}{1}{2016}\n",
      "\n",
      "%Document Head\n",
      "\\dochead{Squib}\n",
      "\n",
      "\\runningtitle{Probing Classifiers}\n",
      "\n",
      "\\runningauthor{Yonatan Belinkov}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "\\title{Probing Classifiers: Promises, Shortcomings, and Advances}\n",
      "\n",
      "\\historydates{Submission received: 4 March 2021; \n",
      "             revised version received: 31 July 2021; \n",
      "             accepted for publication:  8 September 2021}\n",
      "\n",
      "\\author{Yonatan Belinkov\\thanks{Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion.}}\n",
      "\\affil{Technion -- Israel Institute of Technology \\\\ {\\tt belinkov@technion.ac.il}}\n",
      "\n",
      "% \\author{Another Author\\thanks{PITC Building}}\n",
      "% \\affil{Publishing / SPi}\n",
      "\n",
      "% \\author{And Another Author}\n",
      "% \\affil{Publishing / SPi}\n",
      "\n",
      "% \\author{And Yet Another}\n",
      "% \\affil{Publishing / SPi}\n",
      "\n",
      "\\maketitle\n",
      "\n",
      "\\begin{abstract}\n",
      "Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple --- a classifier is trained to predict some linguistic property from a model's representations --- and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This article critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances. \n",
      "\\end{abstract}\n",
      "\n",
      "\\section{Introduction}\n",
      "\n",
      "\\looseness=-1\n",
      "The opaqueness of deep neural network models of natural language processing (NLP) has spurred a line of research into interpreting and analyzing them. \n",
      "Analysis methods may aim to answer questions about a model's structure or its decisions. For instance, one might  ask which parts of a neural neural model are responsible for certain linguistic properties, or which parts of the input led the model to make a certain decision. \n",
      "A common methodology to answer questions about the structure of models is to associate internal representations with external properties, by training a classifier on said representations that predicts a given property. This framework, known as \\mbox{\\textbf{probing classifiers}}, has emerged as a prominent analysis strategy in many studies of NLP models.\\footnote{For an overviews of analysis methods in NLP, see the survey by \\citet{belinkov-glass-2019-analysis}, as well as the tutorials by \\citet{belinkov-etal-2020-interpretability} and \\citet{wallace-etal-2020-interpreting}. For an overview of explanation methods in particular, see the survey by \\citet{danilevsky-etal-2020-survey}.}  \n",
      "\n",
      "\\looseness=-1\n",
      "Despite its apparent success, the probing classifiers paradigm is not without limitations. Critiques have been made about comparative baselines, metrics, the choice of classifier, and the correlational nature of the method. In this short article, we first define the probing classifiers framework, taking care to consider the various involved components. Then we summarize the framework's shortcomings, as well as improvements and advances. \n",
      "This article provides a roadmap for NLP researchers who wish to examine probing classifiers more critically and highlights areas in need of additional research. \n",
      "\n",
      "\n",
      "\\section{The Probing Classifiers Framework} \\label{sec:framework} \n",
      "\n",
      "\n",
      "\n",
      "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property. \n",
      "%\n",
      "However, upon closer inspection, it turns out that much more is involved here. To see this, we now define this framework a bit more formally. \n",
      "\n",
      "Let us denote by $f : x \\mapsto \\hat{y}$ a model that maps input $x$ to output $\\hat{y}$. We call this model the original model. It is trained on some annotated dataset $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\}$, which we refer to as the original dataset. Its performance is evaluated by some measure, denoted $\\textsc{Perf}(f, \\mathcal{D}_O)$.\n",
      "The function $f$ is typically a deep neural network that generates intermediate representations of $x$, for example $f_l(x)$ may denote the representation of $x$ at layer $l$ of $f$.\\footnote{We use $f_l(x)$ to refer more generally to any intermediate output of $f$ when applied to $x$, so the framework includes analyses of other model components, such as attention weights \\cite{clark-etal-2019-bert}.} \n",
      "A probing classifier $g : f_l(x) \\mapsto \\hat{z}$ maps intermediate representations to some property $\\hat{z}$, which is typically some linguistic feature of interest. \n",
      "As a concrete example, $f$ might be a sentiment analysis model, mapping a text $x$ to a sentiment label  $y$, while $g$ might be a classifier mapping intermediate representations $f_l(x)$ to part-of-speech tags $z$.\n",
      "The classifier $g$ is trained and evaluated on some annotated dataset $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\}$, and some performance measure $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ (e.g., accuracy) is reported. Note that the performance measure depends on the probing classifier $g$ and the probing dataset $\\mathcal{D}_P$, as well as on the original model $f$ and the original dataset $\\mathcal{D_O}$.  \n",
      "\n",
      "\n",
      "From an information theoretic perspective, training the probing classifier $g$ can be seen as estimating the mutual information between the intermediate representations $f_l(x)$ and the property $z$ (\\citealt[p. 42]{belinkov:2018:phdthesis}; \\citealt{pimentel-etal-2020-information}; \\citealt{zhu-rudzicz-2020-information}), which we write $\\mathrm{I}(\\mathbf{z} ; \\mathbf{h})$, where  $\\mathbf{z}$ is a random variable ranging over properties $z$ and $\\mathbf{h}$ is a random variable ranging over representations $f_l(x)$.  \n",
      "\n",
      "The above careful definition of the probing classifiers framework reveals that it is comprised of multiple concepts and components, depicted in \\Cref{fig:probing-components-basic}.  The choice of each such component, and the interactions between them, lead to non-trivial questions regarding the design and implementation of any probing classifier experiment. Before we turn to these considerations   in \\Cref{sec:shortcomings-advances}, we briefly review some history and promises of probing classifiers in the next section. \n",
      "\n",
      "\n",
      "\\begin{figure}[h]\n",
      "    \\centering\n",
      "    % \\begin{framed}\n",
      "    \\begin{subfigure}[b]{\\textwidth}\n",
      "    \\centering\n",
      "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
      "        % \\centering\n",
      "        \\toprule\n",
      "         $x \\mapsto y$ & Original task \\\\\n",
      "         $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\} $ & Original dataset \\\\\n",
      "         $f : x \\mapsto y $ & Original model \\\\\n",
      "         $\\textsc{Perf}(f, \\mathcal{D}_O)$ & Performance on the original task \\\\\n",
      "         $f_l(x)$ & Representations of $x$ from $f$\\\\\n",
      "         $f_l(x) \\mapsto z$ & Probing task \\\\\n",
      "         $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\} $ & Probing dataset \\\\\n",
      "         $g : f_l(x) \\mapsto z$ & Probing classifier \\\\\n",
      "         $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) $ & Probing performance  \\\\ \n",
      "         \\bottomrule\n",
      "        \\end{tabular}\n",
      "         \\caption{Basic Components.}\n",
      "         \\label{fig:probing-components-basic}\n",
      "     \\end{subfigure}\n",
      "     \\begin{subfigure}[b]{\\textwidth}\n",
      "     \\centering\n",
      "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
      "        \\toprule          \n",
      "         $\\bar{f} : x \\mapsto y$ & Skyline model or upper bound \\\\ \n",
      "         $\\underline{f} : x \\mapsto y$ & Baseline model \\\\          \n",
      "         $x \\mapsto y_{Rand}$ & Control task \\cite{hewitt-liang-2019-designing} \\\\ \n",
      "         $c : f_l(x) \\mapsto c(f_l(x)) $ & Control function \\cite{pimentel-etal-2020-information} \\\\ \n",
      "         $\\mathcal{D}_{P,Rand}$ & Control task dataset \\cite{hewitt-liang-2019-designing} \\\\ \n",
      "         $\\mathcal{D}_{O,z}$ & Control dataset \\cite{ravichander:2021:eacl} \\\\          \n",
      "         $\\textsc{Sel}(g, f, \\mathcal{D}_O, \\mathcal{D}_P, \\mathcal{D}_{P,Rand})$ & Probing selectivity \\cite{hewitt-liang-2019-designing} \\\\\n",
      "         $ \\mathcal{G}(\\mathbf{z}, \\mathbf{h}, c) $ & Information gain w.r.t control function \\cite{pimentel-etal-2020-information} \\\\ \n",
      "         $\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ & Probe minimum description length \\cite{voita-titov-2020-information} \\\\ \n",
      "         $\\tilde{f}_l(x)$ & Representations of $x$ from $f$, after an intervention \\\\ \n",
      "         \\bottomrule \n",
      "        \\end{tabular}\n",
      "        \\caption{Additional Components.}\n",
      "        \\label{fig:probing-components-extended}\n",
      "        \\vspace{-3pt}\n",
      "    \\end{subfigure}\n",
      "    \\caption{Components comprising the probing classifiers framework.}\n",
      "    \\label{fig:probing-components}\n",
      "    \\vspace{-19pt}\n",
      "\\end{figure}\n",
      "\n",
      "\n",
      "\n",
      "\\section{Promises} \\label{sec:promises}\n",
      "\n",
      "\n",
      "\\looseness=-1\n",
      "Perhaps the first studies that can be cast in the framework of probing classifiers are by \\citet{kohn-2015-whats} and \\citet{gupta-etal-2015-distributional}, who trained classifiers on static word embeddings to predict various morphological, syntactic, and semantic properties. Their goals were to provide more nuanced evaluations of word embeddings compared to prior work, which only integrated them in downstream tasks.  \n",
      "Other early work classified hidden states of a recurrent neural network machine translation system into morpho-syntactic properties \\cite{shi-etal-2016-string}. They were motivated by the end-to-end nature of the neural machine translation system, which, compared to a phrase/syntax-based system, did not explicitly integrate such properties (so they ask: ``What kind of syntactic information is learned, and how much?'').  \n",
      "The framework has taken up a more stable form by several groups who studied sentence embeddings \\cite{ettinger-etal-2016-probing,adi:2017:ICLR,conneau-etal-2018-cram}  and recurrent/recursive neural networks \\cite{belinkov-etal-2017-neural,hupkes2018visualisation}.\\footnote{For chronological completeness, workshop and preprint versions of \\citet{hupkes2018visualisation} and \\citet{adi:2017:ICLR} appeared earlier \\cite{veldhoen2016diagnostic,DBLP:journals/corr/AdiKBLG16}.}  The same idea had been concurrently proposed for investigating computer vision models \\cite{alain2016understanding}. \n",
      "\n",
      "\n",
      "A main motivation in this body of work is the \\emph{opacity} of the representations.\\footnote{``little is known about the information that is captured by different sentence embedding learning mechanisms'' \\cite{adi:2017:ICLR}; ``a poor understanding of what they are capturing'' \\cite{conneau-etal-2018-cram}; ``little is known about what and how much these models learn.'' %about each language and its features''\n",
      "\\cite{belinkov-etal-2017-neural}.} \n",
      "Compared to performance on downstream tasks, probing classifiers aim to provide more nuanced evaluations w.r.t \\emph{simple properties}.\\footnote{``fine-grained measurement of some of the information encoded in sentence embeddings'' \\cite{adi:2017:ICLR}; ``simple linguistic properties of sentences'' \\cite{conneau-etal-2018-cram}; ``assessing the specific semantic information that is being captured in sentence representations'' \\cite{ettinger-etal-2016-probing}.} \n",
      "Indeed, following the initial studies, a plethora of work has applied the framework to various models and properties, alleviating some of the opacity, at least in terms of properties encoded in the representations. See \\citet{belinkov-glass-2019-analysis} for a comprehensive survey up to early 2019.\\footnote{There have also been numerous other studies using the probing classifier framework as is. For a partial list, see \\url{https://github.com/boknilev/nlp-analysis-methods/issues/5}. For recent analyses focusing on the BERT model \\cite{devlin-etal-2019-bert}, see  \\citet{rogers-etal-2020-primer}.}  \n",
      "\n",
      "However, what can be inferred from successful probing performance is less obvious. \n",
      "Good probing performance is often taken to indicate several potential situations: \n",
      "good  \\emph{quality} of the representations w.r.t the probing property,\\footnote{``evaluate the quality of the trained classifier on the given task as a proxy to the quality of the extracted representations'' \\cite{belinkov-etal-2017-neural}.}\n",
      "\\emph{readability} of information found in the representations,\\footnote{``If the classifier succeeds, it means that the pre-trained encoder is storing readable tense information into the embeddings it creates'' \\cite{conneau-etal-2018-cram}.}   \n",
      "or its \\emph{extractability}.\\footnote{``testing for extractability of semantic information by testing classification accuracy..'' \\cite{ettinger-etal-2016-probing}; ``if a sequential model is computing certain information, or merely keeping track of it, it should be possible to extract this information from its internal state space'' \\cite{hupkes2018visualisation}.}\n",
      "In contrast, low probing performance is taken to indicate that the probing property is not present in the representations or is not usable.\\footnote{``low accuracy suggests this information is not represented in the hidden state'' \\cite{hupkes2018visualisation}; ``if we cannot train a classifier to predict some property of a sentence based on its vector representation, then this property is not encoded in the representation (or rather, not encoded in a useful way, considering how the representation is likely to be used)'' \\cite{adi:2017:ICLR}.} \n",
      "%\n",
      "Sometimes, good  performance is taken to indicate \\emph{how} the original model achieves its behavior on the original task \\cite{hupkes2018visualisation}. A linear probing classifier is thought to reveal features that are used by the original model, while a more complex probe ``bears the risk that the classifier infers features that are not actually used by the network'' \\cite{hupkes2018visualisation}.  \n",
      "Often, different terms (\\emph{quality}, \\emph{readability}, \\emph{usability}, etc.) appear abstractedly without precise definitions. \n",
      "\n",
      "\n",
      "As we shall see, some of the above assumptions and conclusions are better accounted for than others by the probing classifiers paradigm. \n",
      "Indeed, the community has recently taken a more critical look at the methodology, which we turn to now.\n",
      "\n",
      "\n",
      "\\section{Shortcomings and Advances} \\label{sec:shortcomings-advances} \n",
      "\n",
      "\n",
      "In light of the promises discussed above, this section reviews several limitations of the probing classifiers framework, as well as existing proposals for addressing them. We discuss comparisons and controls, how to choose the probing classifier, which causal claims can be made, the difference between datasets and tasks, and the need to define the probed properties. \n",
      "We formalize new additional components (\\Cref{fig:probing-components-extended}) in a unified framework, along with the basic components (\\Cref{fig:probing-components-basic}). \n",
      "\n",
      "\n",
      "\\subsection{Comparisons and controls} \n",
      "\n",
      "A first concern with the framework is how to interpret the results of a probing classifier experiment. \n",
      "Suppose we run such an experiment and obtain a performance of $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) = 87.8$. Is that a high/low number? What should we compare it to? \n",
      "We will denote a baseline model with $\\underline{f}$ and an upper bound or skyline model with $\\bar{f}$. \n",
      "\n",
      "Some studies compare with majority baselines \\cite{belinkov-etal-2017-neural,conneau-etal-2018-cram} or with classifiers trained on representations that are thought to be simpler than what the original model $f$ produces, such as static word embeddings \\cite{belinkov-etal-2017-neural,tenney2018what}.  Others advocate for random baselines, training the classifier $g$ on a randomized version of $f$ \\cite{conneau-etal-2018-cram,zhang-bowman-2018-language,tenney2018what,chrupala-etal-2020-analyzing}. These studies show that even random features capture significant information that can be decoded by the probing classifier, so performance on learned features should be viewed in such a perspective. \n",
      "\n",
      "On the other hand, some studies compare $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ to skylines or upper bounds $\\bar{f}$, in an attempt to provide a point of comparison for how far probing performance is from the possible performance on the task of mapping $x \\mapsto z$. \n",
      "Examples include estimating human performance \\cite{conneau-etal-2018-cram}, reporting the state of the art from the literature \\cite{liu-etal-2019-linguistic}, or training a dedicated model to predict $z$ from $x$, without restricting to (frozen) representations from $f$ \\cite{belinkov-etal-2017-evaluating}. \n",
      "\n",
      "\n",
      "Others have proposed to design controls for possible confounders. \\citet{hewitt-liang-2019-designing} observe that the probing performance  $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ may tell us more about the probe $g$ than about the model $f$. The probe $g$ may memorize information from $\\mathcal{D}_P$, rather than evaluate information found in representations $f(x)$.   They design control tasks, which a probe may only solve by memorizing. In particular, they randomize the labels in  $\\mathcal{D}_P$, creating a new dataset  $\\mathcal{D}_{P,Rand}$. Then, they define \\emph{selectivity} as the difference between the probing performance on the probing task and the control task:  $\\textsc{Sel}(g, f, \\mathcal{D}_O, \\mathcal{D}_P, \\mathcal{D}_{P,Rand})$ =  $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) - \\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_{P,Rand})$. They show that probes may have high accuracy, but low selectivity, and that linear probes tend to have high selectivity, while non-linear probes tend to have low selectivity. This indicates that high accuracy of non-linear probes may come from memorization of surface patterns by the probe $g$, rather than from information captured in the representations $f_l(x)$. \n",
      "The control tasks introduced by \\citeauthor{hewitt-liang-2019-designing} are particularly suited for word-level properties $z$ as they evaluate memorization of word types; it is less clear how to apply this idea more broadly, such as in sentence-level properties. \n",
      "\n",
      "Taking an information-theoretic perspective on probing, \\citet{pimentel-etal-2020-information} proposed to use control functions instead of control tasks in order to compare probes. Their control function is any function applied to the representation, $c : f_l(x) \\mapsto c(f_l(x))$, and they compare the information gain, which is the difference in mutual information between the property $z$ and the representation before and after applying the control function:  $ \\mathcal{G}(\\mathbf{z}, \\mathbf{h}, c) =   \\mathrm{I}(\\mathbf{z} ; \\mathbf{h}) - \\mathrm{I}(\\mathbf{z} ; \\mathbf{c(h)})$. \n",
      "While \\citet{pimentel-etal-2020-information} posit that their control function are a better criterion than the control tasks of \\citet{hewitt-liang-2019-designing}, subsequent work showed that the two criteria are almost equivalent, both theoretically and empirically \\cite{zhu-rudzicz-2020-information}. \n",
      "\n",
      "\n",
      "Another kind of control is proposed by \\citet{ravichander:2021:eacl}, who design control datasets, where the linguistic property $z$ is not discriminative w.r.t the original task of mapping $x$ to $y$. That is, they modify $\\mathcal{D}_O$ and create a new dataset, $\\mathcal{D}_{O,z}$, where all examples have the same value for property $z$. Intuitively, a model $f$ trained on $\\mathcal{D}_{O,z}$ should not pick up information about $z$, since it is not useful for the task of $f$. They show that a probe $g$ may learn to predict property $z$ incidentally, even when it is not discriminative w.r.t the original task of mapping $x \\mapsto y$, casting doubts on causal claims concerning the effect that a property encoded in the representation may have on the original task. While they create control datasets for probing sentence-level information, the same idea can be applied to word-level properties.  \n",
      "\n",
      "\n",
      "\n",
      "\\subsection{Which classifier to use?}\n",
      "\n",
      "\n",
      "Another concern is the choice of the probing classifier $g$: \n",
      "What should be its structure? What role does its expressivity play in drawing conclusions about the original model $f$? \n",
      "\n",
      "Some studies advocate for using simple probes, such as linear classifiers \\cite{alain2016understanding,hupkes2018visualisation,liu-etal-2019-linguistic,hall-maudslay-etal-2020-tale}. Somewhat anecdotally, a few studies observed better performance with more complex probes, but reported similar relative trends \\cite{conneau-etal-2018-cram,belinkov:2018:phdthesis}. That is, a ranking \n",
      " $\\textsc{Perf}(g, f_1, \\mathcal{D}_O, \\mathcal{D}_P) > \\textsc{Perf}(g, f_2, \\mathcal{D}_O, \\mathcal{D}_P)$, of two representations $f_1(x)$ and $f_2(x)$,  holds across different probes $g$. \n",
      "However, this pattern may be flipped under alternative measures, such as selectivity \\cite{hewitt-liang-2019-designing}. \n",
      "\n",
      "Several studies considered the complexity of the probe $g$ in more detail. \\citet{pimentel-etal-2020-information} argue that, in order to give the best estimate about the information that model $f$ has about property $z$, the most complex probe should be used. \n",
      "In a more practical view, \\citet{voita-titov-2020-information} propose to measure both the performance of the probe $g$ and its complexity, by estimating the minimum description length of the code required to transmit property $z$ knowing the representations $f_l(x)$: \n",
      "$\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$.\n",
      "Note that this measure again depends on the probe $g$, the model $f$, and their respective datasets $\\mathcal{D}_O$ and  $\\mathcal{D}_P$. \n",
      "They found that MDL provides more information about how a probe $g$ works, for instance by revealing differences in complexity of probes when performing control tasks from $\\mathcal{D}_{P,Rand}$, as in \\citet{hewitt-liang-2019-designing}. \n",
      " \\citet{pimentel-etal-2020-pareto} argue that probing work should report the possible trade-offs between accuracy and complexity, along a range of probes $g$, and call for using probes that are both simple and accurate. \n",
      "While they study a number of linear and  non-linear multi-layered perceptrons, one could extend this idea to other classes of probes. Indeed, \\citet{cao2021low} design a pruning-based probe, which learns a mask on weights of $f$ and obtains a  better accuracy--complexity trade-off than a non-linear probe. \n",
      "\n",
      " \n",
      "\n",
      "Another line of work proposes methods to extract linguistic information from a trained model without learning additional parameters. In particular, much work has used some sort of pairwise importance score between words in a sentence as a signal for inferring linguistic properties, either full syntactic parsing or more fine-grained properties such as coreference resolution. These scores may come from attention weights \\cite{raganato-tiedemann-2018-analysis,clark-etal-2019-bert,marecek-rosa-2019-balustrades,htut2019attention} or from distances between word representations, perhaps including perturbations of the input sentence \\cite{wu-etal-2020-perturbed}.   The pairwise scores can feed into some general parsing algorithm, such as the Chu-Liu Edmonds algorithm \\citeyearpar{10030090917,edmonds1967optimum}.  Alternatively, some work has used representational similarity analysis \\cite{10.3389/neuro.06.004.2008} to measure similarity between word or sentence representations and syntactic properties, both local properties like determining a verb's subject \\cite{lepori-mccoy-2020-picking} and more structured properties like inferring the full syntactic tree \\cite{chrupala-alishahi-2019-correlating}. Also related is work on clustering representations w.r.t linguistic property and classifying by cluster assignment \\cite{zhou-srikumar-2021}.  \n",
      "This line of work can be seen as a parameter-less probing classifier $g$: a linguistic property is inferred from internal model components (representations, attention weights), without needing to learn new parameters. Thus, such work avoids some of the issues about what the probe learns. Additionally, from the perspective of an accuracy--complexity trade-off, such work should perhaps be placed on the low end of the complexity axis, although the complexity of the parsing algorithm could also be taken into account.  \n",
      "\n",
      "\n",
      "\\subsection{Correlation vs.\\ causation} \\label{sec:causal}\n",
      "\n",
      "\n",
      "\n",
      "A main limitation of the probing classifier paradigm is the disconnect between the probing classifier $g$ and the original model $f$. They are trained in two different steps, where $f$ is trained once and only used to generate feature representations $f_l(x)$, which are fed into $g$. Once we have $f_l(x)$, we get a probing performance from $g$, which tells us something about the information in  $f_l(x)$. However, in the process, we have forgotten about the original task assigned to $f$, which was to predict $y$. This raises an important question, which early work has largely taken for granted (\\Cref{sec:promises}): \n",
      "Does model $f$ use the information discovered by probe $g$? \n",
      "In other words, the probing framework may indicate correlations between representations $f_l(x)$ and linguistic property $z$, but it does not tell us whether this property is involved in predictions of $f$. \n",
      "Indeed, several studies pointed out this limitation \\cite{belinkov-glass-2019-analysis}, including reports on a mismatch between performance of the probe, $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$, and performance of the original model, $\\textsc{Perf}(f, \\mathcal{D}_O)$  \\cite{VanmassenhoveDuWay2017}. \n",
      "In contrast, \\citet{lovering2021predicting} find that extractability of a property according to $\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ is correlated with $f$ making predictions consistent with that property. \n",
      "Relatedly, \\citet{tamkin-etal-2020-investigating} find a discrepancy between features $f_l(x)$ obtaining high probing performance, $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$, and features identified as important when fine-tuning $f$ while performing the probing task $f_l(x) \\mapsto z$. They reveal this by randomizing the weights of specific layers when fine-tuning $f$, which can be seen as a kind of intervention.\n",
      "\n",
      "\n",
      "Indeed, a number of studies have proposed improvements to the probing classifier paradigm, which aim to discover causal effects by \\emph{intervening} in representations of the model $f$. \n",
      "\\citet{giulianelli-etal-2018-hood} use gradients from $g$ to modify the representations in $f$ and evaluate how this change affects both the probing performance and the original model performance. In their case, $f$ is a language model and $g$ predicts subject--verb number agreement. They find that their intervention increases probing performance, as may be expected. Interestingly, while in the general language modeling case the intervention has a small effect on the original model performance, $\\textsc{Perf}(f, \\mathcal{D}_O)$, they find an increase in this performance on examples designed to assess number agreement. They conclude that probing classifiers can identify features that are actually used by the model. \n",
      "\\citet{tucker2021modified} also use probe gradients to update the representations $f_l(x)$ w.r.t $z$, resulting in what they call counterfactual representations, and measure the effect on other properties. \n",
      "Similarly, \\citet{elazar2020amnesic} remove certain properties $z$ (such as parts of speech or syntactic dependencies) from representations in $f$ by repeatedly training (linear) probing classifiers $g$ and projecting them out of the representation. This results in a modified representation $\\tilde{f}_l(x)$, which has less information about $z$.  They compare the probing performance to the performance on the original task (in their case, language modeling) after the removal of said features. They find that high probing performance $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ does not necessarily entail a large drop in original task performance after their removal, that is, $\\textsc{Perf}(\\tilde{f}, \\mathcal{D}_O)$. Thus, contrary to \\citet{giulianelli-etal-2018-hood}, they conclude that probing classifiers do not always identify features that are actually used by the model. \n",
      "In a similar vein, \\citet{feder2020causalm} remove properties $z$ from representations in $f$ by training $g$ adversarially. \n",
      "At the same time, another probing classifier $g_C$ is trained positively, aiming to control for properties $z_C$ that should not be removed from $f$. A major difference from standard probing classifiers work is the continued updating of $f$. They find that they can accurately estimate the effect of properties $z$ on downstream tasks performed by $f$ when it is fine-tuned.\\footnote{Other studies that perform interventions to interpret NLP models without involving probing classifiers \\cite[e.g.,][]{bau2018identifying,lakretz-etal-2019-emergence,vig:2020:neurips} are left out of the present scope.}\n",
      "\n",
      "\n",
      "\n",
      "\\subsection{Datasets vs.\\ tasks}\n",
      "\n",
      "\n",
      "The probing paradigm aims to study models performing some task ($f : x \\mapsto \\hat{y}$) via a classifier performing another task ($g: f_l(x) \\mapsto \\hat{z}$). However, in practice these \\emph{tasks} are operationalized via finite \\emph{datsaets}. \n",
      "\\citet{ravichander:2021:eacl}  point out that datasets are imperfect proxies for tasks. \n",
      "Indeed, \n",
      "the effect of the choice of datasets---both the original dataset $\\mathcal{D}_O$ and the probing dataset $\\mathcal{D}_P$---has not been widely studied. Furthermore, we ideally want to disentangle the role of each dataset from the role of the original model $f$ and probing classifier $g$. \n",
      "Unfortunately, models $f$ tend to be trained on different datasets $\\mathcal{D}_O$, making statements about models confounded with issues of datasets. Some prior work acknowledged that conclusions can only be made about the existing \\emph{trained models}, not about general \\emph{architectures} \\cite{liu-etal-2019-linguistic}. \n",
      "However, in an ideal world, we would compare different architectures $\\{f^i\\}$ trained on the same dataset $\\mathcal{D}_O$  or the same  $f$ trained on different datasets $\\{\\mathcal{D}_O^i\\}$. \n",
      "Concerning the latter, \\citet{zhang-etal-2021-need} found that models require less data to encode syntactic and semantic properties compared to commonsense knowledge.\n",
      "More such experiments are currently lacking.  \n",
      "\n",
      "The effect of the probing dataset $\\mathcal{D}_P$---its size, composition, etc.---is similarly not well studied. While some work reported results on multiple datasets when predicting the same property $z$ \\cite[e.g.,][]{belinkov-etal-2017-neural}, more careful investigations are needed. \n",
      "\n",
      "\n",
      "\\subsection{Properties must be pre-defined}\n",
      "\n",
      "\n",
      "Finally, \n",
      "inherent to the probing classifier framework is determining a property $z$ to probe for. This limits the investigation in multiple ways: It constrains the work to existing annotated datasets, which are often limited to English and certain properties. It also requires focusing on properties $z$ that are thought to be relevant to the task of mapping $x \\mapsto y$ a-priori, potentially leading to biased conclusions.\n",
      "In an isolated effort to alleviate this limitation, \\citet{michael-etal-2020-asking} propose to learn latent clusters useful for predicting a property $z$. They discover clusters corresponding to known properties (such as personhood) as well as new categories, which are not usually annotated in common datasets. Still, probing classifiers are so far mainly useful when one has prior expectations about which properties $z$ might be relevant w.r.t a given task. \n",
      "\n",
      "\n",
      "\\section{Summary}\n",
      "\n",
      "\n",
      "Given the various limitations discussed in this article, one might ask: \n",
      "What are probing classifiers good for? In line with the original motivation to alleviate the \\emph{opacity} of learned representations, work using probing classifiers has characterized them along a range of fine-grained properties. \n",
      "However, we have discussed several reservations regarding which insights can be drawn from a probing classifier experiment. \n",
      "Absolute claims about representation \\emph{quality} seem difficult to make. \n",
      "Yet recent improvements to the framework, such as better controls and metrics, allow us to make relative claims and answer questions like how \\emph{extractable} a property is from a representation.  \n",
      "And causal approaches (\\Cref{sec:causal}) may reveal which properties are \\emph{used} by the original model. \n",
      "\n",
      "\n",
      "One might hope that probing classifier experiments would suggest ways to improve the quality of the probed model or to direct it to be better tuned to some use or task. Presently, there are few such successful examples. For instance, {earlier results showing that lower layers in language models focus on local phenomena while higher layers focus on global ones (using probing classifiers and other methods) motivated \\citet{cao-etal-2020-deformer} to decouple a question-answering model, such that lower layers process the question and the passage independently and higher layers process them jointly. \n",
      "An analysis of redundancy in language models (again using probing classifiers and other methods) motivated an efficient transfer-learning procedure \\cite{dalvi-etal-2020-analyzing}. \n",
      "An analysis of phonetic information in layers of a speech recognition systems \\cite{NIPS2017_b069b341} partly motivated \\citet{krishna2018hierarchical} to propose multi-task learning with phonetic supervision on intermediate layers.  \n",
      " \\citet{belinkov-etal-2020-linguistic} discuss how their probing experiments can guide the selection of which machine translation models to use when translating specific languages. \n",
      "Finally, when considering using the representations for some downstream task, probing experiments can indicate which information is encoded, or can easily be extracted, from these representations. \n",
      "\n",
      "\n",
      "\n",
      "To conclude, our critical review of the probing classifiers framework reveals that it is more complicated than may seem. \n",
      "When designing a probing classifier experiment, we advise researchers to take the various controls and alternative measures into account. Naturally, one should clearly define the original task/dataset/model and the probing task/dataset/classifier. It is important to set upper and lower bounds, and to consider proper controls, via either control tasks (for word-level properties) or datasets (for sentence-level properties). Depending on goals, one may want to measure the probe's complexity (if ease of extractability is in question), report the accuracy--complexity trade-off (when designing new probes), or perform an intervention (to measure usage of information by the original model). When possible, using parameter-free probes may circumvent some of the challenges with parameterized probes. \n",
      "We do not argue that every study must perform all the various controls and report all the alternative measures summarized here. \n",
      "However, future work seeking to use probing classifiers would do well to take into account the complexity of the framework, its apparent shortcomings, and available advances. \n",
      "\n",
      "\n",
      "\\begin{acknowledgments}\n",
      "This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 448/20) and by an Azrieli Foundation Early Career Faculty Fellowship.\n",
      "\\end{acknowledgments}\n",
      "\n",
      "\n",
      "\n",
      "\\starttwocolumn\n",
      "\\bibliography{compling_style}\n",
      "\n",
      "\\end{document}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chonk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320384e2",
   "metadata": {},
   "source": [
    "#### endchonk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e1b478f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:05:03.371915Z",
     "start_time": "2024-03-02T19:05:03.364837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35592"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chonk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "970f15fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:09:58.986745Z",
     "start_time": "2024-03-02T19:09:58.975879Z"
    }
   },
   "outputs": [],
   "source": [
    "minichonk = r\"\"\"\\maketitle\n",
    "\n",
    "\\begin{abstract}\n",
    "Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple --- a classifier is trained to predict some linguistic property from a model's representations --- and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This article critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances. \n",
    "\\end{abstract}\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "\\looseness=-1\n",
    "The opaqueness of deep neural network models of natural language processing (NLP) has spurred a line of research into interpreting and analyzing them. \n",
    "Analysis methods may aim to answer questions about a model's structure or its decisions. For instance, one might  ask which parts of a neural neural model are responsible for certain linguistic properties, or which parts of the input led the model to make a certain decision. \n",
    "A common methodology to answer questions about the structure of models is to associate internal representations with external properties, by training a classifier on said representations that predicts a given property. This framework, known as \\mbox{\\textbf{probing classifiers}}, has emerged as a prominent analysis strategy in many studies of NLP models.\\footnote{For an overviews of analysis methods in NLP, see the survey by \\citet{belinkov-glass-2019-analysis}, as well as the tutorials by \\citet{belinkov-etal-2020-interpretability} and \\citet{wallace-etal-2020-interpreting}. For an overview of explanation methods in particular, see the survey by \\citet{danilevsky-etal-2020-survey}.}  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f3a2449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:05:21.754723Z",
     "start_time": "2024-03-02T20:05:21.739813Z"
    }
   },
   "outputs": [],
   "source": [
    "minichonk = r\"\"\"\\section{The Probing Classifiers Framework} \\label{sec:framework} \n",
    "\n",
    "\n",
    "\n",
    "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property. \n",
    "%\n",
    "However, upon closer inspection, it turns out that much more is involved here. To see this, we now define this framework a bit more formally. \n",
    "\n",
    "Let us denote by $f : x \\mapsto \\hat{y}$ a model that maps input $x$ to output $\\hat{y}$. We call this model the original model. It is trained on some annotated dataset $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\}$, which we refer to as the original dataset. Its performance is evaluated by some measure, denoted $\\textsc{Perf}(f, \\mathcal{D}_O)$.\n",
    "The function $f$ is typically a deep neural network that generates intermediate representations of $x$, for example $f_l(x)$ may denote the representation of $x$ at layer $l$ of $f$.\\footnote{We use $f_l(x)$ to refer more generally to any intermediate output of $f$ when applied to $x$, so the framework includes analyses of other model components, such as attention weights \\cite{clark-etal-2019-bert}.} \n",
    "A probing classifier $g : f_l(x) \\mapsto \\hat{z}$ maps intermediate representations to some property $\\hat{z}$, which is typically some linguistic feature of interest. \n",
    "As a concrete example, $f$ might be a sentiment analysis model, mapping a text $x$ to a sentiment label  $y$, while $g$ might be a classifier mapping intermediate representations $f_l(x)$ to part-of-speech tags $z$.\n",
    "The classifier $g$ is trained and evaluated on some annotated dataset $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\}$, and some performance measure $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ (e.g., accuracy) is reported. Note that the performance measure depends on the probing classifier $g$ and the probing dataset $\\mathcal{D}_P$, as well as on the original model $f$ and the original dataset $\\mathcal{D_O}$.  \n",
    "\n",
    "\n",
    "From an information theoretic perspective, training the probing classifier $g$ can be seen as estimating the mutual information between the intermediate representations $f_l(x)$ and the property $z$ (\\citealt[p. 42]{belinkov:2018:phdthesis}; \\citealt{pimentel-etal-2020-information}; \\citealt{zhu-rudzicz-2020-information}), which we write $\\mathrm{I}(\\mathbf{z} ; \\mathbf{h})$, where  $\\mathbf{z}$ is a random variable ranging over properties $z$ and $\\mathbf{h}$ is a random variable ranging over representations $f_l(x)$.  \n",
    "\n",
    "The above careful definition of the probing classifiers framework reveals that it is comprised of multiple concepts and components, depicted in \\Cref{fig:probing-components-basic}.  The choice of each such component, and the interactions between them, lead to non-trivial questions regarding the design and implementation of any probing classifier experiment. Before we turn to these considerations   in \\Cref{sec:shortcomings-advances}, we briefly review some history and promises of probing classifiers in the next section. \n",
    "\n",
    "\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    % \\begin{framed}\n",
    "    \\begin{subfigure}[b]{\\textwidth}\n",
    "    \\centering\n",
    "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
    "        % \\centering\n",
    "        \\toprule\n",
    "         $x \\mapsto y$ & Original task \\\\\n",
    "         $\\mathcal{D}_O = \\{x^{(i)}, y^{(i)}\\} $ & Original dataset \\\\\n",
    "         $f : x \\mapsto y $ & Original model \\\\\n",
    "         $\\textsc{Perf}(f, \\mathcal{D}_O)$ & Performance on the original task \\\\\n",
    "         $f_l(x)$ & Representations of $x$ from $f$\\\\\n",
    "         $f_l(x) \\mapsto z$ & Probing task \\\\\n",
    "         $\\mathcal{D}_P = \\{x^{(i)}, z^{(i)}\\} $ & Probing dataset \\\\\n",
    "         $g : f_l(x) \\mapsto z$ & Probing classifier \\\\\n",
    "         $\\textsc{Perf}(g, f, \\mathcal{D}_O, \\mathcal{D}_P) $ & Probing performance  \\\\ \n",
    "         \\bottomrule\n",
    "        \\end{tabular}\n",
    "         \\caption{Basic Components.}\n",
    "         \\label{fig:probing-components-basic}\n",
    "     \\end{subfigure}\n",
    "     \\begin{subfigure}[b]{\\textwidth}\n",
    "     \\centering\n",
    "        \\begin{tabular}{l @{\\hskip 1em} l } \n",
    "        \\toprule          \n",
    "         $\\bar{f} : x \\mapsto y$ & Skyline model or upper bound \\\\ \n",
    "         $\\underline{f} : x \\mapsto y$ & Baseline model \\\\          \n",
    "         $x \\mapsto y_{Rand}$ & Control task \\cite{hewitt-liang-2019-designing} \\\\ \n",
    "         $c : f_l(x) \\mapsto c(f_l(x)) $ & Control function \\cite{pimentel-etal-2020-information} \\\\ \n",
    "         $\\mathcal{D}_{P,Rand}$ & Control task dataset \\cite{hewitt-liang-2019-designing} \\\\ \n",
    "         $\\mathcal{D}_{O,z}$ & Control dataset \\cite{ravichander:2021:eacl} \\\\          \n",
    "         $\\textsc{Sel}(g, f, \\mathcal{D}_O, \\mathcal{D}_P, \\mathcal{D}_{P,Rand})$ & Probing selectivity \\cite{hewitt-liang-2019-designing} \\\\\n",
    "         $ \\mathcal{G}(\\mathbf{z}, \\mathbf{h}, c) $ & Information gain w.r.t control function \\cite{pimentel-etal-2020-information} \\\\ \n",
    "         $\\textsc{MDL}(g, f, \\mathcal{D}_O, \\mathcal{D}_P)$ & Probe minimum description length \\cite{voita-titov-2020-information} \\\\ \n",
    "         $\\tilde{f}_l(x)$ & Representations of $x$ from $f$, after an intervention \\\\ \n",
    "         \\bottomrule \n",
    "        \\end{tabular}\n",
    "        \\caption{Additional Components.}\n",
    "        \\label{fig:probing-components-extended}\n",
    "        \\vspace{-3pt}\n",
    "    \\end{subfigure}\n",
    "    \\caption{Components comprising the probing classifiers framework.}\n",
    "    \\label{fig:probing-components}\n",
    "    \\vspace{-19pt}\n",
    "\\end{figure}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a773da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "53dcc2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:05:34.095590Z",
     "start_time": "2024-03-02T20:05:25.286003Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": minichonk}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    max_tokens=4096,\n",
    "    n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c73b6d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:05:34.105615Z",
     "start_time": "2024-03-02T20:05:34.099636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Probing Classifiers Framework\n",
      "\n",
      "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property.\n",
      "\n",
      "However, upon closer inspection, it turns out that much more is involved here. To see this, we now define this framework a bit more formally.\n",
      "\n",
      "Let us denote by f: x maps to y-hat a model that maps input x to output y-hat. We call this model the original model. It is trained on some annotated dataset D_O = {x^(i), y^(i)}, which we refer to as the original dataset. Its performance is evaluated by some measure, denoted Perf(f, D_O). \n",
      "The function f is typically a deep neural network that generates intermediate representations of x, for example f_l(x) may denote the representation of x at layer l of f. \n",
      "A probing classifier g: f_l(x) maps to z-hat maps intermediate representations to some property z-hat, which is typically some linguistic feature of interest. \n",
      "As a concrete example, f might be a sentiment analysis model, mapping a text x to a sentiment label y, while g might be a classifier mapping intermediate representations f_l(x) to part-of-speech tags z.\n",
      "The classifier g is trained and evaluated on some annotated dataset D_P = {x^(i), z^(i)}, and some performance measure Perf(g, f, D_O, D_P) (e.g., accuracy) is reported. Note that the performance measure depends on the probing classifier g and the probing dataset D_P, as well as on the original model f and the original dataset D_O.\n",
      "\n",
      "From an information theoretic perspective, training the probing classifier g can be seen as estimating the mutual information between the intermediate representations f_l(x) and the property z (Belinkov, 2018; Pimentel et al., 2020; Zhu and Rudzicz, 2020), which we write I(z-hat ; h-hat), where z-hat is a random variable ranging over properties z and h-hat is a random variable ranging over representations f_l(x).\n",
      "\n",
      "The above careful definition of the probing classifiers framework reveals that it is comprised of multiple concepts and components, depicted in Figure 1. The choice of each such component, and the interactions between them, lead to non-trivial questions regarding the design and implementation of any probing classifier experiment. Before we turn to these considerations in Section 2, we briefly review some history and promises of probing classifiers in the next section.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "862b168b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:07:31.923315Z",
     "start_time": "2024-03-02T19:07:31.908800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3420"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f771cff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:07:52.663513Z",
     "start_time": "2024-03-02T19:07:52.657912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_completion.choices[0].message.content.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9956682a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:23:22.484472Z",
     "start_time": "2024-03-02T19:23:22.479531Z"
    }
   },
   "outputs": [],
   "source": [
    "text_for_speech = r\"\"\"Taking an information-theoretic perspective on probing, Pimentel et al. (2020) proposed to use control functions instead of control tasks in order to compare probes. Their control function is any function applied to the representation, c : f_l(x) maps to c(f_l(x)), and they compare the information gain, which is the difference in mutual information between the property z and the representation before and after applying the control function: G(z, h, c) = I(z ; h) - I(z ; c(h)).\n",
    "While Pimentel et al. (2020) posit that their control function are a better criterion than the control tasks of Hewitt and Liang (2019), subsequent work showed that the two criteria are almost equivalent, both theoretically and empirically. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ba66c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:24:49.577669Z",
     "start_time": "2024-03-02T19:24:49.563471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taking an information-theoretic perspective on probing, Pimentel et al. (2020) proposed to use control functions instead of control tasks in order to compare probes. Their control function is any function applied to the representation, c : f_l(x) maps to c(f_l(x)), and they compare the information gain, which is the difference in mutual information between the property z and the representation before and after applying the control function: G(z, h, c) = I(z ; h) - I(z ; c(h)).\\nWhile Pimentel et al. (2020) posit that their control function are a better criterion than the control tasks of Hewitt and Liang (2019), subsequent work showed that the two criteria are almost equivalent, both theoretically and empirically. '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_for_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3c88b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:23:53.188197Z",
     "start_time": "2024-03-02T19:23:44.281998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/7_02v1xx1nx_p2rj9mxjqzzh0000gn/T/ipykernel_31469/155931865.py:8: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "speech_file_path = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=text_for_speech\n",
    ")\n",
    "\n",
    "response.to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f9fbd",
   "metadata": {},
   "source": [
    "## putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4f52467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:47:40.215508Z",
     "start_time": "2024-03-02T19:47:40.209976Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_latex_by_section(latex_content):\n",
    "    # Pattern to match section and subsection commands\n",
    "    pattern = r'(?=(\\\\section\\{.*?\\}|\\\\subsection\\{.*?\\}))'\n",
    "    \n",
    "    # Split the content by the pattern and filter out any empty strings\n",
    "    parts = [part for part in re.split(pattern, latex_content) if part.strip()]\n",
    "    \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "401c3664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:47:40.633311Z",
     "start_time": "2024-03-02T19:47:40.626254Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_latex_by_section(latex_content):\n",
    "    # Pattern to match section and subsection commands\n",
    "    pattern = r'(\\\\section\\{.*?\\}|\\\\subsection\\{.*?\\})'\n",
    "    \n",
    "    # Split the content by the pattern, keeping the delimiters\n",
    "    parts = re.split(pattern, latex_content)\n",
    "    \n",
    "    # Combine each command with its following content\n",
    "    combined_parts = []\n",
    "    for i in range(1, len(parts) - 1, 2):\n",
    "        combined_parts.append(parts[i] + parts[i + 1])\n",
    "    \n",
    "    # Add the last part if it doesn't end with a command\n",
    "    if len(parts) % 2 == 1:\n",
    "        combined_parts.append(parts[-1])\n",
    "    \n",
    "    return combined_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4528ff4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:47:41.552808Z",
     "start_time": "2024-03-02T19:47:41.548340Z"
    }
   },
   "outputs": [],
   "source": [
    "sections = split_latex_by_section(chonk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a9f30089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:53:29.961606Z",
     "start_time": "2024-03-02T19:53:27.808928Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': '1 validation error for Request\\nbody -> input\\n  ensure this value has at most 4096 characters (type=value_error.any_str.max_length; limit_value=4096)', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qd/7_02v1xx1nx_p2rj9mxjqzzh0000gn/T/ipykernel_31469/4278887403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspeech_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"belinkov.mp3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = client.audio.speech.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tts-1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvoice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"alloy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/resources/audio/speech.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, voice, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;34m\"/audio/speech\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     def patch(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 889\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         return self._process_response(\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': '1 validation error for Request\\nbody -> input\\n  ensure this value has at most 4096 characters (type=value_error.any_str.max_length; limit_value=4096)', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "speech_file_path = \"belinkov.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=text\n",
    ")\n",
    "\n",
    "response.to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88346cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T19:49:27.961298Z",
     "start_time": "2024-03-02T19:47:41.935590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 11/11 [01:46<00:00,  9.64s/it]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "for section in tqdm(sections): \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": section}\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        max_tokens=4096,\n",
    "        n=1\n",
    "    )\n",
    "    snippet = chat_completion.choices[0].message.content\n",
    "    text += f\"\"\"{snippet}\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d5f57bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:35:50.502264Z",
     "start_time": "2024-03-02T20:28:16.883622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/11 [00:00<?, ?it/s]/var/folders/qd/7_02v1xx1nx_p2rj9mxjqzzh0000gn/T/ipykernel_31469/2814344313.py:8: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n",
      "100%|█████████████████████████████████████████| 11/11 [07:11<00:00, 39.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='belinkov.mp3'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_audio(snippet, index):\n",
    "    speech_file_path = f\"snippet_{index}.mp3\"\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"alloy\",\n",
    "        input=snippet\n",
    "    )\n",
    "    response.stream_to_file(speech_file_path)\n",
    "    return speech_file_path\n",
    "\n",
    "def generate_snippet(section):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": section}\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        max_tokens=4096,\n",
    "        n=1\n",
    "    )\n",
    "    snippet = chat_completion.choices[0].message.content\n",
    "    return snippet\n",
    "\n",
    "# Create a list to store the paths of the individual audio files\n",
    "audio_file_paths = []\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for i, section in enumerate(tqdm(sections)):\n",
    "    # Generate the chat completion\n",
    "    snippet = generate_snippet(section)\n",
    "    \n",
    "    # Check if the snippet is too long\n",
    "    if len(snippet) > 4096:\n",
    "        # Split the snippet at an arbitrary newline\n",
    "        split_index = snippet.find('\\n', len(snippet) // 4)\n",
    "        snippet_part1 = snippet[:split_index]\n",
    "        snippet_part2 = snippet[split_index + 1:]\n",
    "        \n",
    "        # rerun cleaning for both parts\n",
    "        snippet_part1 = generate_snippet(snippet_part1)\n",
    "        snippet_part2 = generate_snippet(snippet_part2)\n",
    "        \n",
    "        # Generate audio for both parts\n",
    "        audio_file_paths.append(generate_audio(snippet_part1, f\"{i}_1\"))\n",
    "        audio_file_paths.append(generate_audio(snippet_part2, f\"{i}_2\"))\n",
    "        \n",
    "        text += f\"{snippet_part1} \\n\\n\"\n",
    "        text += f\"{snippet_part2} \\n\\n\"\n",
    "    else:\n",
    "        # Generate audio for the snippet\n",
    "        audio_file_paths.append(generate_audio(snippet, i))\n",
    "        text += f\"{snippet} \\n\\n\"\n",
    "\n",
    "# Concatenate all the audio files\n",
    "combined_audio = AudioSegment.empty()\n",
    "for path in audio_file_paths:\n",
    "    audio = AudioSegment.from_mp3(path)\n",
    "    combined_audio += audio\n",
    "\n",
    "# Export the combined audio to a single MP3 file\n",
    "combined_audio.export(\"belinkov.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d953cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:35:57.776135Z",
     "start_time": "2024-03-02T20:35:57.767378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Introduction\n",
      "\n",
      "The opaqueness of deep neural network models of natural language processing (NLP) has spurred a line of research into interpreting and analyzing them. Analysis methods may aim to answer questions about a model's structure or its decisions. For instance, one might ask which parts of a neural model are responsible for certain linguistic properties, or which parts of the input led the model to make a certain decision. A common methodology to answer questions about the structure of models is to associate internal representations with external properties, by training a classifier on said representations that predicts a given property. This framework, known as probing classifiers, has emerged as a prominent analysis strategy in many studies of NLP models.1\n",
      "\n",
      "Despite its apparent success, the probing classifiers paradigm is not without limitations. Critiques have been made about comparative baselines, metrics, the choice of classifier, and the correlational nature of the method. In this short article, we first define the probing classifiers framework, taking care to consider the various involved components. Then we summarize the framework's shortcomings, as well as improvements and advances. This article provides a roadmap for NLP researchers who wish to examine probing classifiers more critically and highlights areas in need of additional research. \n",
      "\n",
      "The Probing Classifiers Framework\n",
      "\n",
      "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property.\n",
      "\n",
      "However, upon closer inspection, it turns out that much more is involved here. To see this, we now define this framework a bit more formally.\n",
      "\n",
      "Let us denote by f : x maps to y-hat a model that maps input x to output y-hat. We call this model the original model. It is trained on some annotated dataset D_O = {x^(i), y^(i)}, which we refer to as the original dataset. Its performance is evaluated by some measure, denoted Perf(f, D_O).\n",
      "The function f is typically a deep neural network that generates intermediate representations of x, for example f_l(x) may denote the representation of x at layer l of f. Footnote 1: We use f_l(x) to refer more generally to any intermediate output of f when applied to x, so the framework includes analyses of other model components, such as attention weights (Clark et al. 2019). \n",
      "A probing classifier g : f_l(x) maps to z-hat maps intermediate representations to some property z-hat, which is typically some linguistic feature of interest.\n",
      "As a concrete example, f might be a sentiment analysis model, mapping a text x to a sentiment label y, while g might be a classifier mapping intermediate representations f_l(x) to part-of-speech tags z.\n",
      "The classifier g is trained and evaluated on some annotated dataset D_P = {x^(i), z^(i)}, and some performance measure Perf(g, f, D_O, D_P) (for example, accuracy) is reported. Note that the performance measure depends on the probing classifier g and the probing dataset D_P, as well as on the original model f and the original dataset D_O.\n",
      "\n",
      "From an information theoretic perspective, training the probing classifier g can be seen as estimating the mutual information between the intermediate representations f_l(x) and the property z (Belinkov, 2018; Pimentel et al. 2020; Zhu and Rudzicz, 2020), which we write I(z-hat; h-hat), where z-hat is a random variable ranging over properties z and h-hat is a random variable ranging over representations f_l(x).\n",
      "\n",
      "The above careful definition of the probing classifiers framework reveals that it is comprised of multiple concepts and components, depicted in Figure 1. The choice of each such component, and the interactions between them, lead to non-trivial questions regarding the design and implementation of any probing classifier experiment. Before we turn to these considerations in Section 3, we briefly review some history and promises of probing classifiers in the next section. \n",
      "\n",
      "Section Promises\n",
      "\n",
      "Perhaps the first studies that can be cast in the framework of probing classifiers are by Kohn et al. (2015) and Gupta et al. (2015), who trained classifiers on static word embeddings to predict various morphological, syntactic, and semantic properties. Their goals were to provide more nuanced evaluations of word embeddings compared to prior work, which only integrated them in downstream tasks.  \n",
      "Other early work classified hidden states of a recurrent neural network machine translation system into morpho-syntactic properties (Shi et al., 2016). They were motivated by the end-to-end nature of the neural machine translation system, which, compared to a phrase/syntax-based system, did not explicitly integrate such properties (so they ask: \"What kind of syntactic information is learned, and how much?\").  \n",
      "The framework has taken up a more stable form by several groups who studied sentence embeddings (Ettinger et al., 2016; Adi et al., 2017; Conneau et al., 2018) and recurrent/recursive neural networks (Belinkov et al., 2017; Hupkes, 2018). For chronological completeness, workshop and preprint versions of Hupkes et al. (2018) and Adi et al. (2017) appeared earlier. The same idea had been concurrently proposed for investigating computer vision models (Alain, 2016). \n",
      "\n",
      "A main motivation in this body of work is the opacity of the representations. \"little is known about the information that is captured by different sentence embedding learning mechanisms\" (Adi et al., 2017); \"a poor understanding of what they are capturing\" (Conneau et al., 2018); \"little is known about what and how much these models learn.\" about each language and its features (Belinkov et al., 2017). \n",
      "Compared to performance on downstream tasks, probing classifiers aim to provide more nuanced evaluations with simple properties. \"fine-grained measurement of some of the information encoded in sentence embeddings\" (Adi et al., 2017); \"simple linguistic properties of sentences\" (Conneau et al., 2018); \"assessing the specific semantic information that is being captured in sentence representations\" (Ettinger et al., 2016). \n",
      "Indeed, following the initial studies, a plethora of work has applied the framework to various models and properties, alleviating some of the opacity, at least in terms of properties encoded in the representations. See Belinkov and Glass (2019) for a comprehensive survey up to early 2019. \n",
      "There have also been numerous other studies using the probing classifier framework as is. For a partial list, see the website NLP Analysis Methods. For recent analyses focusing on the BERT model (Devlin et al., 2019), see Rogers et al., 2020. \n",
      "\n",
      "However, what can be inferred from successful probing performance is less obvious. \n",
      "Good probing performance is often taken to indicate several potential situations: \n",
      "good quality of the representations with respect to the probing property, \n",
      "readability of information found in the representations, or its extractability. \n",
      "In contrast, low probing performance is taken to indicate that the probing property is not present in the representations or is not usable. \n",
      "Sometimes, good performance is taken to indicate how the original model achieves its behavior on the original task. A linear probing classifier is thought to reveal features that are used by the original model. \n",
      "Often, different terms (quality, readability, usability, etc.) appear abstractedly without precise definitions. \n",
      "\n",
      "As we shall see, some of the above assumptions and conclusions are better accounted for than others by the probing classifiers paradigm. \n",
      "Indeed, the community has recently taken a more critical look at the methodology, which we turn to now. \n",
      "\n",
      "Section Shortcomings and Advances. Label section shortcomings advances. \n",
      "\n",
      "In light of the promises discussed above, this section reviews several limitations of the probing classifiers framework, as well as existing proposals for addressing them. We discuss comparisons and controls, how to choose the probing classifier, which causal claims can be made, the difference between datasets and tasks, and the need to define the probed properties. \n",
      "We formalize new additional components (see Figure probing components extended) in a unified framework, along with the basic components (see Figure probing components basic). \n",
      "\n",
      "Comparisons and controls\n",
      "\n",
      "A first concern with the framework is how to interpret the results of a probing classifier experiment. Suppose we run such an experiment and obtain a performance of \"Performance (g, f, D_O, D_P)\" equals 87.8. Is that a high/low number? What should we compare it to? We will denote a baseline model with \"f̲\" and an upper bound or skyline model with \"f¯\".\n",
      "\n",
      "Some studies compare with majority baselines (Belinkov et al., 2017; Conneau et al., 2018) or with classifiers trained on representations that are thought to be simpler than what the original model \"f\" produces, such as static word embeddings (Belinkov et al., 2017; Tenney et al., 2018). Others advocate for random baselines, training the classifier \"g\" on a randomized version of \"f\" (Conneau et al., 2018; Zhang and Bowman, 2018; Tenney et al., 2018; Chrupala et al., 2020). These studies show that even random features capture significant information that can be decoded by the probing classifier, so performance on learned features should be viewed in such a perspective.\n",
      "\n",
      "On the other hand, some studies compare \"Performance (g, f, D_O, D_P)\" to skylines or upper bounds \"f¯\", in an attempt to provide a point of comparison for how far probing performance is from the possible performance on the task of mapping x to z. Examples include estimating human performance (Conneau et al., 2018), reporting the state of the art from the literature (Liu et al., 2019), or training a dedicated model to predict \"z\" from \"x\", without restricting to (frozen) representations from \"f\" (Belinkov et al., 2017). \n",
      "\n",
      "Others have proposed to design controls for possible confounders. Hewitt and Liang (2019) observe that the probing performance Performance (g, f, D_O, D_P) may tell us more about the probe g than about the model f. The probe g may memorize information from D_P, rather than evaluate information found in representations f(x). They design control tasks, which a probe may only solve by memorizing. In particular, they randomize the labels in D_P, creating a new dataset D_P,Rand. Then, they define selectivity as the difference between the probing performance on the probing task and the control task: Selectivity (g, f, D_O, D_P, D_P,Rand) equals Performance (g, f, D_O, D_P) minus Performance (g, f, D_O, D_P,Rand). They show that probes may have high accuracy, but low selectivity, and that linear probes tend to have high selectivity, while non-linear probes tend to have low selectivity. This indicates that high accuracy of non-linear probes may come from memorization of surface patterns by the probe g, rather than from information captured in the representations f(x).\n",
      "\n",
      "The control tasks introduced by Hewitt and Liang (2019) are particularly suited for word-level properties z as they evaluate memorization of word types; it is less clear how to apply this idea more broadly, such as in sentence-level properties.\n",
      "\n",
      "Taking an information-theoretic perspective on probing, Pimentel et al. (2020) proposed to use control functions instead of control tasks in order to compare probes. Their control function is any function applied to the representation, c : f(x) maps to c(f(x)), and they compare the information gain, which is the difference in mutual information between the property z and the representation before and after applying the control function: G(z, h, c) equals I(z ; h) minus I(z ; c(h)). While Pimentel et al. (2020) posit that their control function are a better criterion than the control tasks of Hewitt and Liang (2019), subsequent work showed that the two criteria are almost equivalent, both theoretically and empirically (Zhu and Rudzicz, 2020).\n",
      "\n",
      "Another kind of control is proposed by Ravichander et al. (2021), who design control datasets, where the linguistic property z is not discriminative with respect to the original task of mapping x to y. That is, they modify D_O and create a new dataset, D_O,z, where all examples have the same value for property z. Intuitively, a model f trained on D_O,z should not pick up information about z, since it is not useful for the task of f. They show that a probe g may learn to predict property z incidentally, even when it is not discriminative with respect to the original task of mapping x to y, casting doubts on causal claims concerning the effect that a property encoded in the representation may have on the original task. While they create control datasets for probing sentence-level information, the same idea can be applied to word-level properties. \n",
      "\n",
      "Which classifier to use?\n",
      "\n",
      "Another concern is the choice of the probing classifier $g$: \n",
      "What should be its structure? What role does its expressivity play in drawing conclusions about the original model $f$? \n",
      "\n",
      "Some studies advocate for using simple probes, such as linear classifiers (Alain et al., 2016; Hupkes et al., 2018; Liu et al., 2019; Hall et al., 2020). Somewhat anecdotally, a few studies observed better performance with more complex probes, but reported similar relative trends (Conneau et al., 2018; Belinkov, 2018). That is, a ranking  \n",
      "\"Performance of $g$ on $f_1$ with $\\mathcal{D}_O$, $\\mathcal{D}_P$ is greater than performance of $g$ on $f_2$ with $\\mathcal{D}_O$, $\\mathcal{D}_P$,\" of two representations $f_1(x)$ and $f_2(x)$, holds across different probes $g$. \n",
      "However, this pattern may be flipped under alternative measures, such as selectivity (Hewitt and Liang, 2019). \n",
      "\n",
      "Several studies considered the complexity of the probe $g$ in more detail. Pimentel et al. (2020) argue that, in order to give the best estimate about the information that model $f$ has about property $z$, the most complex probe should be used. \n",
      "In a more practical view, Voita and Titov (2020) propose to measure both the performance of the probe $g$ and its complexity, by estimating the minimum description length of the code required to transmit property $z$ knowing the representations $f_l(x)$: \n",
      "MDL of $g, f, \\mathcal{D}_O, \\mathcal{D}_P$.\n",
      "Note that this measure again depends on the probe $g$, the model $f$, and their respective datasets $\\mathcal{D}_O$ and  $\\mathcal{D}_P$. \n",
      "They found that MDL provides more information about how a probe $g$ works, for instance by revealing differences in complexity of probes when performing control tasks from $\\mathcal{D}_{P,Rand}$, as in Hewitt and Liang (2019). \n",
      "Pimentel et al. (2020) argue that probing work should report the possible trade-offs between accuracy and complexity, along a range of probes $g$, and call for using probes that are both simple and accurate. \n",
      "While they study a number of linear and non-linear multi-layered perceptrons, one could extend this idea to other classes of probes. Indeed, Cao et al. (2021) design a pruning-based probe, which learns a mask on weights of $f$ and obtains a better accuracy--complexity trade-off than a non-linear probe. \n",
      "\n",
      "Another line of work proposes methods to extract linguistic information from a trained model without learning additional parameters. In particular, much work has used some sort of pairwise importance score between words in a sentence as a signal for inferring linguistic properties, either full syntactic parsing or more fine-grained properties such as coreference resolution. These scores may come from attention weights (Raganato & Tiedemann, 2018; Clark et al., 2019; Marecek & Rosa, 2019; Htut, 2019) or from distances between word representations, perhaps including perturbations of the input sentence (Wu et al., 2020). The pairwise scores can feed into some general parsing algorithm, such as the Chu-Liu Edmonds algorithm (Edmonds, 1967). Alternatively, some work has used representational similarity analysis to measure similarity between word or sentence representations and syntactic properties, both local properties like determining a verb's subject (Lepori & McCoy, 2020) and more structured properties like inferring the full syntactic tree (Chrupala & Alishahi, 2019). Also related is work on clustering representations with respect to linguistic property and classifying by cluster assignment (Zhou & Srikumar, 2021).  \n",
      "This line of work can be seen as a parameter-less probing classifier $g$: a linguistic property is inferred from internal model components (representations, attention weights), without needing to learn new parameters. Thus, such work avoids some of the issues about what the probe learns. Additionally, from the perspective of an accuracy--complexity trade-off, such work should perhaps be placed on the low end of the complexity axis, although the complexity of the parsing algorithm could also be taken into account.   \n",
      "\n",
      "Subsection: Correlation versus causation\n",
      "\n",
      "A main limitation of the probing classifier paradigm is the disconnect between the probing classifier g and the original model f. They are trained in two different steps, where f is trained once and only used to generate feature representations f sub l of x, which are fed into g. Once we have f sub l of x, we get a probing performance from g, which tells us something about the information in f sub l of x. However, in the process, we have forgotten about the original task assigned to f, which was to predict y. This raises an important question, which early work has largely taken for granted (see Section 2): Does model f use the information discovered by probe g? In other words, the probing framework may indicate correlations between representations f sub l of x and linguistic property z, but it does not tell us whether this property is involved in predictions of f. Indeed, several studies pointed out this limitation (Belinkov and Glass, 2019), including reports on a mismatch between performance of the probe, Perf(g, f, D sub O, D sub P), and performance of the original model, Perf(f, D sub O) (Vanmassenhove & DuWay, 2017). In contrast, Lovering et al. (2021) find that extractability of a property according to MDL(g, f, D sub O, D sub P) is correlated with f making predictions consistent with that property. Relatedly, Tamkin et al. (2020) find a discrepancy between features f sub l of x obtaining high probing performance, Perf(g, f, D sub O, D sub P), and features identified as important when fine-tuning f while performing the probing task f sub l of x maps to z. They reveal this by randomizing the weights of specific layers when fine-tuning f, which can be seen as a kind of intervention. \n",
      "\n",
      "Indeed, a number of studies have proposed improvements to the probing classifier paradigm, which aim to discover causal effects by intervening in representations of the model f. Giulianelli et al. (2018) use gradients from g to modify the representations in f and evaluate how this change affects both the probing performance and the original model performance. In their case, f is a language model and g predicts subject-verb number agreement. They find that their intervention increases probing performance, as may be expected. Interestingly, while in the general language modeling case the intervention has a small effect on the original model performance, Perf(f, D_O), they find an increase in this performance on examples designed to assess number agreement. They conclude that probing classifiers can identify features that are actually used by the model. Tucker et al. (2021) also use probe gradients to update the representations f_l(x) with respect to z, resulting in what they call counterfactual representations, and measure the effect on other properties. Similarly, Elazar et al. (2020) remove certain properties z (such as parts of speech or syntactic dependencies) from representations in f by repeatedly training (linear) probing classifiers g and projecting them out of the representation. This results in a modified representation f_l(x), which has less information about z. They compare the probing performance to the performance on the original task (in their case, language modeling) after the removal of said features. They find that high probing performance Perf(g, f, D_O, D_P) does not necessarily entail a large drop in original task performance after their removal, that is, Perf(f~, D_O). Thus, contrary to Giulianelli et al. (2018), they conclude that probing classifiers do not always identify features that are actually used by the model. In a similar vein, Feder et al. (2020) remove properties z from representations in f by training g adversarially. At the same time, another probing classifier g_C is trained positively, aiming to control for properties z_C that should not be removed from f. A major difference from standard probing classifiers work is the continued updating of f. They find that they can accurately estimate the effect of properties z on downstream tasks performed by f when it is fine-tuned. Other studies that perform interventions to interpret NLP models without involving probing classifiers (e.g., Bau et al., 2018; Lakretz et al., 2019; Vig et al., 2020) are left out of the present scope. \n",
      "\n",
      "Subsection: Datasets vs. tasks\n",
      "\n",
      "The probing paradigm aims to study models performing some task (f: x maps to y-hat) via a classifier performing another task (g: f sub l of x maps to z-hat). However, in practice these tasks are operationalized via finite datasets. Ravichander et al. (2021) point out that datasets are imperfect proxies for tasks. Indeed, the effect of the choice of datasets—both the original dataset D sub O and the probing dataset D sub P—has not been widely studied. Furthermore, we ideally want to disentangle the role of each dataset from the role of the original model f and probing classifier g. Unfortunately, models f tend to be trained on different datasets D sub O, making statements about models confounded with issues of datasets. Some prior work acknowledged that conclusions can only be made about the existing trained models, not about general architectures (Liu et al., 2019). However, in an ideal world, we would compare different architectures {f to the power of i} trained on the same dataset D sub O or the same f trained on different datasets {D sub O to the power of i}. Concerning the latter, Zhang et al. (2021) found that models require less data to encode syntactic and semantic properties compared to commonsense knowledge. More such experiments are currently lacking.\n",
      "\n",
      "The effect of the probing dataset D sub P—its size, composition, etc.—is similarly not well studied. While some work reported results on multiple datasets when predicting the same property z (e.g., Belinkov et al., 2017), more careful investigations are needed. \n",
      "\n",
      "Properties must be pre-defined. \n",
      "\n",
      "Finally, inherent to the probing classifier framework is determining a property z to probe for. This limits the investigation in multiple ways: It constrains the work to existing annotated datasets, which are often limited to English and certain properties. It also requires focusing on properties z that are thought to be relevant to the task of mapping x to y a-priori, potentially leading to biased conclusions.\n",
      "\n",
      "In an isolated effort to alleviate this limitation, Michael et al. (2020) propose to learn latent clusters useful for predicting a property z. They discover clusters corresponding to known properties (such as personhood) as well as new categories, which are not usually annotated in common datasets. Still, probing classifiers are so far mainly useful when one has prior expectations about which properties z might be relevant with respect to a given task. \n",
      "\n",
      "Summary\n",
      "\n",
      "Given the various limitations discussed in this article, one might ask: What are probing classifiers good for? In line with the original motivation to alleviate the opacity of learned representations, work using probing classifiers has characterized them along a range of fine-grained properties. However, we have discussed several reservations regarding which insights can be drawn from a probing classifier experiment. Absolute claims about representation quality seem difficult to make. Yet recent improvements to the framework, such as better controls and metrics, allow us to make relative claims and answer questions like how extractable a property is from a representation. And causal approaches (section 'causal') may reveal which properties are used by the original model.\n",
      "\n",
      "One might hope that probing classifier experiments would suggest ways to improve the quality of the probed model or to direct it to be better tuned to some use or task. Presently, there are few such successful examples. For instance, earlier results showing that lower layers in language models focus on local phenomena while higher layers focus on global ones (using probing classifiers and other methods) motivated Cao et al. (2020) to decouple a question-answering model, such that lower layers process the question and the passage independently and higher layers process them jointly. An analysis of redundancy in language models (again using probing classifiers and other methods) motivated an efficient transfer-learning procedure. An analysis of phonetic information in layers of a speech recognition systems partly motivated Krishna et al. to propose multi-task learning with phonetic supervision on intermediate layers. Belinkov et al. discuss how their probing experiments can guide the selection of which machine translation models to use when translating specific languages. Finally, when considering using the representations for some downstream task, probing experiments can indicate which information is encoded, or can easily be extracted, from these representations.\n",
      "\n",
      "To conclude, our critical review of the probing classifiers framework reveals that it is more complicated than may seem. When designing a probing classifier experiment, we advise researchers to take the various controls and alternative measures into account. Naturally, one should clearly define the original task/dataset/model and the probing task/dataset/classifier. It is important to set upper and lower bounds, and to consider proper controls, via either control tasks (for word-level properties) or datasets (for sentence-level properties). Depending on goals, one may want to measure the probe's complexity (if ease of extractability is in question), report the accuracy-complexity trade-off (when designing new probes), or perform an intervention (to measure usage of information by the original model). When possible, using parameter-free probes may circumvent some of the challenges with parameterized probes. We do not argue that every study must perform all the various controls and report all the alternative measures summarized here. However, future work seeking to use probing classifiers would do well to take into account the complexity of the framework, its apparent shortcomings, and available advances.\n",
      "\n",
      "Acknowledgments\n",
      "\n",
      "This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 448/20) and by an Azrieli Foundation Early Career Faculty Fellowship.\n",
      "\n",
      "Bibliography\n",
      "\n",
      "\\bibliography{compling_style}\n",
      "\n",
      "End of document. \n",
      "\n",
      "Given the various limitations discussed in this article, one might ask: \n",
      "What are probing classifiers good for? In line with the original motivation to alleviate the opacity of learned representations, work using probing classifiers has characterized them along a range of fine-grained properties. \n",
      "However, we have discussed several reservations regarding which insights can be drawn from a probing classifier experiment. \n",
      "Absolute claims about representation quality seem difficult to make. \n",
      "Yet recent improvements to the framework, such as better controls and metrics, allow us to make relative claims and answer questions like how extractable a property is from a representation.  \n",
      "And causal approaches (section causal) may reveal which properties are used by the original model. \n",
      "\n",
      "\n",
      "One might hope that probing classifier experiments would suggest ways to improve the quality of the probed model or to direct it to be better tuned to some use or task. Presently, there are few such successful examples. For instance, earlier results showing that lower layers in language models focus on local phenomena while higher layers focus on global ones (using probing classifiers and other methods) motivated Cao et al. 2020 to decouple a question-answering model, such that lower layers process the question and the passage independently and higher layers process them jointly. \n",
      "An analysis of redundancy in language models (again using probing classifiers and other methods) motivated an efficient transfer-learning procedure (Dalvi et al. 2020). \n",
      "An analysis of phonetic information in layers of a speech recognition systems (NIPS 2017) partly motivated Krishna et al. 2018 to propose multi-task learning with phonetic supervision on intermediate layers.  \n",
      "Belinkov et al. 2020 discuss how their probing experiments can guide the selection of which machine translation models to use when translating specific languages. \n",
      "Finally, when considering using the representations for some downstream task, probing experiments can indicate which information is encoded, or can easily be extracted, from these representations. \n",
      "\n",
      "\n",
      "\n",
      "To conclude, our critical review of the probing classifiers framework reveals that it is more complicated than may seem. \n",
      "When designing a probing classifier experiment, we advise researchers to take the various controls and alternative measures into account. Naturally, one should clearly define the original task/dataset/model and the probing task/dataset/classifier. It is important to set upper and lower bounds, and to consider proper controls, via either control tasks (for word-level properties) or datasets (for sentence-level properties). Depending on goals, one may want to measure the probe's complexity (if ease of extractability is in question), report the accuracy--complexity trade-off (when designing new probes), or perform an intervention (to measure usage of information by the original model). When possible, using parameter-free probes may circumvent some of the challenges with parameterized probes. \n",
      "We do not argue that every study must perform all the various controls and report all the alternative measures summarized here. \n",
      "However, future work seeking to use probing classifiers would do well to take into account the complexity of the framework, its apparent shortcomings, and available advances. \n",
      "\n",
      "\n",
      "Acknowledgments:\n",
      "This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 448/20) and by an Azrieli Foundation Early Career Faculty Fellowship. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "282c51e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:25:12.186891Z",
     "start_time": "2024-03-02T20:25:12.181684Z"
    }
   },
   "outputs": [],
   "source": [
    "split_index = snippet.find('\\n', len(snippet) // 4)\n",
    "snippet_part1 = snippet[:split_index]\n",
    "snippet_part2 = snippet[split_index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "03939e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T20:25:15.883058Z",
     "start_time": "2024-03-02T20:25:15.875591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Section: Correlation versus causation\\n\\nA main limitation of the probing classifier paradigm is the disconnect between the probing classifier $g$ and the original model $f$. They are trained in two different steps, where $f$ is trained once and only used to generate feature representations $f_l(x)$, which are fed into $g$. Once we have $f_l(x)$, we get a probing performance from $g$, which tells us something about the information in $f_l(x)$. However, in the process, we have forgotten about the original task assigned to $f$, which was to predict $y$. This raises an important question, which early work has largely taken for granted (Section: Promises): Does model $f$ use the information discovered by probe $g$? In other words, the probing framework may indicate correlations between representations $f_l(x)$ and linguistic property $z$, but it does not tell us whether this property is involved in predictions of $f. Indeed, several studies pointed out this limitation (Belinkov & Glass, 2019), including reports on a mismatch between performance of the probe, Perf($g, f, \\\\mathcal{D}_O, \\\\mathcal{D}_P$), and performance of the original model, Perf($f, \\\\mathcal{D}_O$) (Vanmassenhove & DuWay, 2017). In contrast, Lovering et al. (2021) find that extractability of a property according to MDL($g, f, \\\\mathcal{D}_O, \\\\mathcal{D}_P$) is correlated with $f$ making predictions consistent with that property. Relatedly, Tamkin et al. (2020) find a discrepancy between features $f_l(x)$ obtaining high probing performance, Perf($g, f, \\\\mathcal{D}_O, \\\\mathcal{D}_P$), and features identified as important when fine-tuning $f$ while performing the probing task $f_l(x) \\\\mapsto z$. They reveal this by randomizing the weights of specific layers when fine-tuning $f$, which can be seen as a kind of intervention.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de36ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
